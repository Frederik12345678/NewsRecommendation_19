{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.ticker as mticker\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import polars as pl # used to read the .parquet files so its important\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Add the parent directory (or specify path to 'utils' if it's higher)\n",
    "dir = os.path.abspath(os.path.join(os.getcwd(), '..', '..')) \n",
    "sys.path.append(dir)\n",
    "\n",
    "from dataloader.NRMSdataloader import NRMSDataLoader\n",
    "from models.nrms import NRMSModelPytorch\n",
    "from eval.metricEval import MetricEvaluator, AucScore, MrrScore, NdcgScore\n",
    "\n",
    "# Now you can import from utils\n",
    "from utils import add_known_user_column, add_prediction_scores\n",
    "from utils import get_transformers_word_embeddings, concat_str_columns,convert_text2encoding_with_transformers, create_article_id_to_value_mapping\n",
    "from utils import get_script_directory, slice_join_dataframes, truncate_history,sampling_strategy_wu2019, create_binary_labels_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_path = get_script_directory()\n",
    "\n",
    "DEFAULT_IS_BEYOND_ACCURACY_COL = \"is_beyond_accuracy\"\n",
    "\n",
    "\n",
    "PATH = Path(basic_path+\"/Data\")\n",
    "TRAIN_VAL_SPLIT = f\"ebnerd_demo\"  # [ebnerd_demo, ebnerd_small, ebnerd_large]\n",
    "TEST_SPLIT = f\"ebnerd_testset\"  # \"ebnerd_testset\", \"ebnerd_testset_gt\"\n",
    "\n",
    "#_____________________Training____________________________\n",
    "# Reads the behaviors file from training data\n",
    "df_behaviors_train = df_behaviors = pl.scan_parquet(\n",
    "    PATH.joinpath(TRAIN_VAL_SPLIT, \"train\", \"behaviors.parquet\")\n",
    ")\n",
    "# Reads the history file from training data\n",
    "df_history_train = df_behaviors = pl.scan_parquet(\n",
    "    PATH.joinpath(TRAIN_VAL_SPLIT, \"train\", \"history.parquet\")\n",
    ")\n",
    "\n",
    "#_____________________Validation____________________________\n",
    "# Reads the behaviors file from Validation data\n",
    "df_behaviors_val = df_behaviors = pl.scan_parquet(\n",
    "    PATH.joinpath(TRAIN_VAL_SPLIT, \"validation\", \"behaviors.parquet\")\n",
    ")\n",
    "# Reads the History file from Validation data\n",
    "df_history_val = df_behaviors = pl.scan_parquet(\n",
    "    PATH.joinpath(TRAIN_VAL_SPLIT, \"validation\", \"history.parquet\")\n",
    ")\n",
    "\n",
    "#_____________________Test____________________________\n",
    "# Reads the behaviors file from test data\n",
    "df_behaviors_test = df_behaviors = (\n",
    "    pl.scan_parquet(PATH.joinpath(TEST_SPLIT, \"test\", \"behaviors.parquet\"))\n",
    "    .filter(~pl.col(DEFAULT_IS_BEYOND_ACCURACY_COL))\n",
    "    .drop(DEFAULT_IS_BEYOND_ACCURACY_COL)\n",
    ")\n",
    "# Reads the History file from test data\n",
    "df_history_test = df_behaviors = pl.scan_parquet(\n",
    "    PATH.joinpath(TEST_SPLIT, \"test\", \"history.parquet\")\n",
    ")\n",
    "\n",
    "# ?? seem we already read this file ? but now without .drop(DEFAULT_IS_BEYOND_ACCURACY_COL)\n",
    "df_behaviors_test_ba = df_behaviors = pl.scan_parquet(\n",
    "    PATH.joinpath(TEST_SPLIT, \"test\", \"behaviors.parquet\")\n",
    ").filter(pl.col(DEFAULT_IS_BEYOND_ACCURACY_COL))\n",
    "\n",
    "#_____________________Reads Articles ??____________________________\n",
    "df_articles = pl.scan_parquet(PATH.joinpath(TEST_SPLIT,\"articles.parquet\")).collect()\n",
    "\n",
    "PLOT_PATH = Path(\"plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom src.ebrec.utils._constants import (\\n    DEFAULT_HISTORY_ARTICLE_ID_COL, = f\"{\"article_id\"}_fixed\"\\n    DEFAULT_CLICKED_ARTICLES_COL, = \"article_ids_clicked\"\\n    DEFAULT_INVIEW_ARTICLES_COL, = \"article_ids_inview\"\\n    DEFAULT_IMPRESSION_ID_COL, = \"impression_id\"\\n    DEFAULT_SUBTITLE_COL, = \"subtitle\"\\n    DEFAULT_LABELS_COL, = \"labels\"\\n    DEFAULT_TITLE_COL, =  \"title\"\\n    DEFAULT_USER_COL, = \"user_id\"\\n)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "from src.ebrec.utils._constants import (\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL, = f\"{\"article_id\"}_fixed\"\n",
    "    DEFAULT_CLICKED_ARTICLES_COL, = \"article_ids_clicked\"\n",
    "    DEFAULT_INVIEW_ARTICLES_COL, = \"article_ids_inview\"\n",
    "    DEFAULT_IMPRESSION_ID_COL, = \"impression_id\"\n",
    "    DEFAULT_SUBTITLE_COL, = \"subtitle\"\n",
    "    DEFAULT_LABELS_COL, = \"labels\"\n",
    "    DEFAULT_TITLE_COL, =  \"title\"\n",
    "    DEFAULT_USER_COL, = \"user_id\"\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ebnerd_from_path(path: Path, history_size: int = 30) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Load ebnerd - function\n",
    "    \"\"\"\n",
    "    df_history = (\n",
    "        pl.scan_parquet(path.joinpath(\"history.parquet\"))\n",
    "        .select(\"user_id\", \"article_id_fixed\")\n",
    "        .pipe(\n",
    "            truncate_history,\n",
    "            column=\"article_id_fixed\",\n",
    "            history_size=history_size,\n",
    "            padding_value=0,\n",
    "            enable_warning=False,\n",
    "        )\n",
    "    )\n",
    "    df_behaviors = (\n",
    "        pl.scan_parquet(path.joinpath(\"behaviors.parquet\"))\n",
    "        .collect()\n",
    "        .pipe(\n",
    "            slice_join_dataframes,\n",
    "            df2=df_history.collect(),\n",
    "            on=\"user_id\",\n",
    "            how=\"left\",\n",
    "        )\n",
    "    )\n",
    "    return df_behaviors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_path = get_script_directory()\n",
    "\n",
    "PATH = Path(basic_path+\"/Data\")\n",
    "DATASPLIT = f\"ebnerd_demo\"  # [ebnerd_demo, ebnerd_small, ebnerd_large]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>article_id_fixed</th><th>article_ids_inview</th><th>article_ids_clicked</th><th>impression_id</th><th>labels</th></tr><tr><td>u32</td><td>list[i32]</td><td>list[i64]</td><td>list[i64]</td><td>u32</td><td>list[i8]</td></tr></thead><tbody><tr><td>741821</td><td>[0, 0, … 9768708]</td><td>[9778351, 9778375, … 9778422]</td><td>[9778375]</td><td>269734580</td><td>[0, 1, … 0]</td></tr><tr><td>1647768</td><td>[9762058, 8362617, … 9728166]</td><td>[9775846, 9777296, … 9777296]</td><td>[9776337]</td><td>426852735</td><td>[0, 0, … 0]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 6)\n",
       "┌─────────┬───────────────────┬───────────────────┬──────────────────┬───────────────┬─────────────┐\n",
       "│ user_id ┆ article_id_fixed  ┆ article_ids_invie ┆ article_ids_clic ┆ impression_id ┆ labels      │\n",
       "│ ---     ┆ ---               ┆ w                 ┆ ked              ┆ ---           ┆ ---         │\n",
       "│ u32     ┆ list[i32]         ┆ ---               ┆ ---              ┆ u32           ┆ list[i8]    │\n",
       "│         ┆                   ┆ list[i64]         ┆ list[i64]        ┆               ┆             │\n",
       "╞═════════╪═══════════════════╪═══════════════════╪══════════════════╪═══════════════╪═════════════╡\n",
       "│ 741821  ┆ [0, 0, … 9768708] ┆ [9778351,         ┆ [9778375]        ┆ 269734580     ┆ [0, 1, … 0] │\n",
       "│         ┆                   ┆ 9778375, …        ┆                  ┆               ┆             │\n",
       "│         ┆                   ┆ 9778422]          ┆                  ┆               ┆             │\n",
       "│ 1647768 ┆ [9762058,         ┆ [9775846,         ┆ [9776337]        ┆ 426852735     ┆ [0, 0, … 0] │\n",
       "│         ┆ 8362617, …        ┆ 9777296, …        ┆                  ┆               ┆             │\n",
       "│         ┆ 9728166]          ┆ 9777296]          ┆                  ┆               ┆             │\n",
       "└─────────┴───────────────────┴───────────────────┴──────────────────┴───────────────┴─────────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COLUMNS = [\n",
    "    \"user_id\",\n",
    "    \"article_id_fixed\",\n",
    "    \"article_ids_inview\",\n",
    "    \"article_ids_clicked\",\n",
    "    \"impression_id\",\n",
    "]\n",
    "HISTORY_SIZE = 10\n",
    "FRACTION = 0.01\n",
    "\n",
    "df_train = (\n",
    "    ebnerd_from_path(PATH.joinpath(DATASPLIT, \"train\"), history_size=HISTORY_SIZE)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(\n",
    "        sampling_strategy_wu2019,\n",
    "        npratio=4,\n",
    "        shuffle=True,\n",
    "        with_replacement=True,\n",
    "        seed=123,\n",
    "    )\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION)\n",
    ")\n",
    "# =>\n",
    "df_validation = (\n",
    "    ebnerd_from_path(PATH.joinpath(DATASPLIT, \"validation\"), history_size=HISTORY_SIZE)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION)\n",
    ")\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 21)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>article_id</th><th>title</th><th>subtitle</th><th>last_modified_time</th><th>premium</th><th>body</th><th>published_time</th><th>image_ids</th><th>article_type</th><th>url</th><th>ner_clusters</th><th>entity_groups</th><th>topics</th><th>category</th><th>subcategory</th><th>category_str</th><th>total_inviews</th><th>total_pageviews</th><th>total_read_time</th><th>sentiment_score</th><th>sentiment_label</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>datetime[μs]</td><td>bool</td><td>str</td><td>datetime[μs]</td><td>list[i64]</td><td>str</td><td>str</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>i16</td><td>list[i16]</td><td>str</td><td>i32</td><td>i32</td><td>f32</td><td>f32</td><td>str</td></tr></thead><tbody><tr><td>3037230</td><td>&quot;Ishockey-spiller: Jeg troede j…</td><td>&quot;ISHOCKEY: Ishockey-spilleren S…</td><td>2023-06-29 06:20:57</td><td>false</td><td>&quot;Ambitionerne om at komme til U…</td><td>2003-08-28 08:55:00</td><td>null</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/sport/…</td><td>[]</td><td>[]</td><td>[&quot;Kriminalitet&quot;, &quot;Kendt&quot;, … &quot;Mindre ulykke&quot;]</td><td>142</td><td>[327, 334]</td><td>&quot;sport&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9752</td><td>&quot;Negative&quot;</td></tr><tr><td>3044020</td><td>&quot;Prins Harry tvunget til dna-te…</td><td>&quot;Hoffet tvang Prins Harry til a…</td><td>2023-06-29 06:21:16</td><td>false</td><td>&quot;Den britiske tabloidavis The S…</td><td>2005-06-29 08:47:00</td><td>[3097307, 3097197, 3104927]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/underh…</td><td>[&quot;Harry&quot;, &quot;James Hewitt&quot;]</td><td>[&quot;PER&quot;, &quot;PER&quot;]</td><td>[&quot;Kriminalitet&quot;, &quot;Kendt&quot;, … &quot;Personfarlig kriminalitet&quot;]</td><td>414</td><td>[432]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.7084</td><td>&quot;Negative&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 21)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ article_i ┆ title     ┆ subtitle  ┆ last_modi ┆ … ┆ total_pag ┆ total_rea ┆ sentiment ┆ sentimen │\n",
       "│ d         ┆ ---       ┆ ---       ┆ fied_time ┆   ┆ eviews    ┆ d_time    ┆ _score    ┆ t_label  │\n",
       "│ ---       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ i32       ┆           ┆           ┆ datetime[ ┆   ┆ i32       ┆ f32       ┆ f32       ┆ str      │\n",
       "│           ┆           ┆           ┆ μs]       ┆   ┆           ┆           ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 3037230   ┆ Ishockey- ┆ ISHOCKEY: ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9752    ┆ Negative │\n",
       "│           ┆ spiller:  ┆ Ishockey- ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Jeg       ┆ spilleren ┆ 06:20:57  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ troede j… ┆ S…        ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3044020   ┆ Prins     ┆ Hoffet    ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.7084    ┆ Negative │\n",
       "│           ┆ Harry     ┆ tvang     ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ tvunget   ┆ Prins     ┆ 06:21:16  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ til       ┆ Harry til ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ dna-te…   ┆ a…        ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles = pl.read_parquet(PATH.joinpath(DATASPLIT,\"articles.parquet\"))\n",
    "df_articles.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORMER_MODEL_NAME = \"FacebookAI/xlm-roberta-base\"\n",
    "TEXT_COLUMNS_TO_USE = [\"subtitle\", \"title\"]\n",
    "MAX_TITLE_LENGTH = 30\n",
    "\n",
    "# LOAD HUGGINGFACE:\n",
    "transformer_model = AutoModel.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "transformer_tokenizer = AutoTokenizer.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "\n",
    "# We'll init the word embeddings using the\n",
    "word2vec_embedding = get_transformers_word_embeddings(transformer_model)\n",
    "#\n",
    "df_articles, cat_cal = concat_str_columns(df_articles, columns=TEXT_COLUMNS_TO_USE)\n",
    "df_articles, token_col_title = convert_text2encoding_with_transformers(\n",
    "    df_articles, transformer_tokenizer, cat_cal, max_length=MAX_TITLE_LENGTH\n",
    ")\n",
    "# =>\n",
    "article_mapping = create_article_id_to_value_mapping(\n",
    "    df=df_articles, value_col=token_col_title\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from typing import Any\n",
    "\n",
    "# Assuming `NRMSDataLoader` is the class you provided above\n",
    "\n",
    "class PyTorchNRMSDataLoader(Dataset):\n",
    "    def __init__(self, tf_dataloader: NRMSDataLoader):\n",
    "        \"\"\"\n",
    "        Wraps the TensorFlow DataLoader to work with PyTorch.\n",
    "        \n",
    "        Args:\n",
    "        - tf_dataloader: An instance of the NRMSDataLoader.\n",
    "        \"\"\"\n",
    "        self.tf_dataloader = tf_dataloader\n",
    "    \n",
    "    def __len__(self):\n",
    "        # The length of the PyTorch Dataset is the same as the number of batches in TensorFlow's DataLoader\n",
    "        return len(self.tf_dataloader)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> tuple:\n",
    "        \"\"\"\n",
    "        Fetches a batch of data from the TensorFlow DataLoader and converts it to PyTorch format.\n",
    "        \n",
    "        Args:\n",
    "        - idx: The index of the batch.\n",
    "        \n",
    "        Returns:\n",
    "        - A tuple of (his_input_title, pred_input_title) and batch_y as PyTorch tensors.\n",
    "        \"\"\"\n",
    "        # Get the batch from the TensorFlow DataLoader\n",
    "        (his_input_title, pred_input_title), batch_y = self.tf_dataloader[idx]\n",
    "        \n",
    "        # Convert numpy arrays to PyTorch tensors\n",
    "        his_input_title = torch.tensor(his_input_title, dtype=torch.float32)\n",
    "        pred_input_title = torch.tensor(pred_input_title, dtype=torch.float32)\n",
    "        batch_y = torch.tensor(batch_y, dtype=torch.float32)\n",
    "        \n",
    "        return (his_input_title, pred_input_title), batch_y\n",
    "\n",
    "\n",
    "# Initialize your TensorFlow-based NRMSDataLoader (as shown in your example)\n",
    "train_dataloader = NRMSDataLoader(\n",
    "    behaviors=df_train,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=\"article_id_fixed\",\n",
    "    eval_mode=False,\n",
    "    batch_size=64,\n",
    ")\n",
    "\n",
    "val_dataloader = NRMSDataLoader(\n",
    "    behaviors=df_validation,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=\"article_id_fixed\",\n",
    "    eval_mode=True,\n",
    "    batch_size=64,\n",
    ")\n",
    "\n",
    "# Wrap the TensorFlow DataLoader into a PyTorch Dataset\n",
    "train_pytorch_dataset = PyTorchNRMSDataLoader(train_dataloader)\n",
    "val_pytorch_dataset = PyTorchNRMSDataLoader(val_dataloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10, 30])\n",
      "torch.Size([64, 5, 30])\n",
      "torch.Size([64, 10, 30])\n",
      "torch.Size([64, 5, 30])\n",
      "torch.Size([64, 10, 30])\n",
      "torch.Size([64, 5, 30])\n",
      "torch.Size([56, 10, 30])\n",
      "torch.Size([56, 5, 30])\n",
      "torch.Size([727, 10, 30])\n",
      "torch.Size([738, 10, 30])\n",
      "torch.Size([814, 10, 30])\n",
      "torch.Size([672, 10, 30])\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# Now you can use these DataLoader objects with your PyTorch model\n",
    "for (his_input_title, pred_input_title), batch_y in train_pytorch_dataset:\n",
    "    print(his_input_title.shape)\n",
    "    print(pred_input_title.shape)\n",
    "\n",
    "for (his_input_title, pred_input_title), batch_y in val_pytorch_dataset:\n",
    "    print(his_input_title.shape)\n",
    "\n",
    "print(len(train_pytorch_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    d_k = query.size(-1)\n",
    "    print(f\"Attention: query shape: {query.shape}, key shape: {key.shape}, value shape: {value.shape}\")\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "    print(f\"Attention: scores shape: {scores.shape}\")\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -math.inf)\n",
    "    p_attn = F.softmax(scores, dim = -1)\n",
    "    print(f\"Attention: p_attn shape: {p_attn.shape}\")\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    output = torch.matmul(p_attn, value)\n",
    "    print(f\"Attention: output shape: {output.shape}\")\n",
    "    return output, p_attn\n",
    "\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    \"\"\"A simple Multi-head attention layer.\"\"\"\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model*h\n",
    "        print(\"d_k\", self.d_k)\n",
    "        print(\"d_model\",d_model)\n",
    "        print(\"h\",h)\n",
    "        self.h = h\n",
    "        self.linears = nn.ModuleList([nn.Linear(768, self.d_k) for _ in range(4)])\n",
    "        self.attn = None # store the attention maps\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        nbatches = query.size(0)\n",
    "        print(f\"MultiHeadedAttention: input query shape: {query.shape}, key shape: {key.shape}, value shape: {value.shape}\")\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "\n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k \n",
    "        \n",
    "        query, key, value = [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2) for l, x in zip(self.linears, (query, key, value))]\n",
    "        print(f\"MultiHeadedAttention: reshaped query shape: {query.shape}, key shape: {key.shape}, value shape: {value.shape}\")\n",
    "\n",
    "        # 2) Apply attention on all the projected vectors in batch. \n",
    "        x, self.attn = attention(query, key, value, mask=mask, dropout=self.dropout)\n",
    "        print(f\"MultiHeadedAttention: attention output shape: {x.shape}\")\n",
    "\n",
    "        # 3) \"Concat\" using a view and apply a final linear. \n",
    "        x = x.transpose(1, 2).contiguous().view(nbatches, -1, self.h * self.d_k)\n",
    "        print(f\"MultiHeadedAttention: concatenated output shape: {x.shape}\")\n",
    "        return self.linears[-1](x)\n",
    "\n",
    "class AttLayer2_torch(nn.Module):\n",
    "    \"\"\"Soft alignment attention implementation in PyTorch.\"\"\"\n",
    "    \n",
    "    def __init__(self, dim=200, seed=0):\n",
    "        super(AttLayer2_torch, self).__init__()\n",
    "        self.dim = dim\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "        # Initialize W, b, and q but do not specify input dimension yet\n",
    "        self.W = None\n",
    "        self.b = nn.Parameter(torch.zeros(dim))\n",
    "        self.q = nn.Parameter(torch.empty(dim, 1))\n",
    "        \n",
    "        # Initialize q using Xavier initialization\n",
    "        nn.init.xavier_uniform_(self.q)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Dynamically initialize W based on the input's feature size\n",
    "        if self.W is None:\n",
    "            input_dim = inputs.size(-1)  # Get the feature dimension of the input\n",
    "            self.W = nn.Parameter(torch.empty(input_dim, self.dim))\n",
    "            nn.init.xavier_uniform_(self.W)  # Xavier initialization for W\n",
    "        \n",
    "        # Apply soft attention mechanism\n",
    "        attention_scores = torch.tanh(inputs @ self.W + self.b) @ self.q\n",
    "        print(f\"AttLayer2_torch: attention_scores shape: {attention_scores.shape}\")\n",
    "        attention_weights = F.softmax(attention_scores.squeeze(-1), dim=-1).unsqueeze(-1)\n",
    "        print(f\"AttLayer2_torch: attention_weights shape: {attention_weights.shape}\")\n",
    "        weighted_inputs = inputs * attention_weights\n",
    "        output = torch.sum(weighted_inputs, dim=1)\n",
    "        print(f\"AttLayer2_torch: output shape: {output.shape}\")\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "class NRMSModelPytorch_2(nn.Module):\n",
    "    def __init__(self, hparams, word2vec_embedding=None, word_emb_dim=300, vocab_size=32000, seed=None):\n",
    "        super(NRMSModelPytorch_2, self).__init__()\n",
    "        self.hparams = hparams\n",
    "        self.seed = seed\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        # Initialize word embeddings\n",
    "        if word2vec_embedding is None:\n",
    "            self.word2vec_embedding = torch.randn(vocab_size, word_emb_dim)\n",
    "        else:\n",
    "            self.word2vec_embedding = torch.from_numpy(word2vec_embedding).float()\n",
    "        self.embedding_layer = nn.Embedding.from_pretrained(self.word2vec_embedding, freeze=False)\n",
    "\n",
    "        # Build model components\n",
    "        self.news_encoder = self._build_newsencoder()\n",
    "        self.user_encoder = self._build_userencoder(self.news_encoder)\n",
    "\n",
    "        # Define optimizer and loss\n",
    "        self.criterion = self._get_loss(hparams.loss)\n",
    "        self.optimizer = self._get_opt(hparams.optimizer, hparams.learning_rate)\n",
    "\n",
    "    def _get_loss(self, loss):\n",
    "        if loss == \"cross_entropy_loss\":\n",
    "            return nn.CrossEntropyLoss()\n",
    "        elif loss == \"log_loss\":\n",
    "            return nn.BCELoss()\n",
    "        else:\n",
    "            raise ValueError(f\"this loss not defined {loss}\")\n",
    "\n",
    "    def _get_opt(self, optimizer, lr):\n",
    "        if optimizer == \"adam\":\n",
    "            return optim.Adam(self.parameters(), lr=lr)\n",
    "        else:\n",
    "            raise ValueError(f\"this optimizer not defined {optimizer}\")\n",
    "\n",
    "    def _build_userencoder(self, titleencoder):\n",
    "        # Define user encoder using SelfAttention and AttLayer2 modules\n",
    "        class UserEncoder(nn.Module):\n",
    "            def __init__(self, hparams, titleencoder):\n",
    "                super(UserEncoder, self).__init__()\n",
    "                self.titleencoder = titleencoder\n",
    "                self.attention = MultiHeadedAttention(hparams.head_num, hparams.head_num)\n",
    "                self.att_layer = AttLayer2_torch(hparams.attention_hidden_dim)\n",
    "\n",
    "            def forward(self, his_input_title):\n",
    "                # Encode each news in the history\n",
    "                click_title_presents = torch.stack([self.titleencoder(title) for title in his_input_title], dim=1)\n",
    "                y = self.attention(click_title_presents,click_title_presents,click_title_presents)\n",
    "                user_present = self.att_layer(y)\n",
    "                return user_present\n",
    "\n",
    "        return UserEncoder(self.hparams, titleencoder)\n",
    "\n",
    "    def _build_newsencoder(self):\n",
    "        # Define news encoder using embedding and attention layers\n",
    "        class NewsEncoder(nn.Module):\n",
    "            def __init__(self, embedding_layer, hparams, seed):\n",
    "                super(NewsEncoder, self).__init__()\n",
    "                self.embedding = embedding_layer\n",
    "                self.dropout1 = nn.Dropout(hparams.dropout)  # Use attribute access here\n",
    "                self.attention = MultiHeadedAttention(hparams.head_num, hparams.head_dim)\n",
    "                self.dropout2 = nn.Dropout(hparams.dropout)  # Use attribute access here\n",
    "                self.att_layer = AttLayer2_torch(hparams.attention_hidden_dim, seed=seed)\n",
    "\n",
    "\n",
    "            def forward(self, sequences_input_title):\n",
    "                # Convert input to LongTensor\n",
    "                sequences_input_title = sequences_input_title.long()\n",
    "                embedded_sequences_title = self.embedding(sequences_input_title)\n",
    "                y = self.dropout1(embedded_sequences_title)\n",
    "\n",
    "                y = self.attention(y,y,y)\n",
    "                y = self.dropout2(y)\n",
    "                pred_title = self.att_layer(y)\n",
    "                return pred_title\n",
    "\n",
    "        return NewsEncoder(self.embedding_layer, self.hparams, self.seed)\n",
    "\n",
    "    def forward(self, his_input_title, pred_input_title):\n",
    "        print(f\"NRMSModelPytorch_2: his_input_title shape: {his_input_title.shape}, pred_input_title shape: {pred_input_title.shape}\")\n",
    "        \n",
    "        user_vector = self.user_encoder(his_input_title)\n",
    "        print(f\"NRMSModelPytorch_2: user_vector shape: {user_vector.shape}\")\n",
    "        \n",
    "        news_vectors = torch.stack([self.news_encoder(news) for news in pred_input_title], dim=1)\n",
    "        print(f\"NRMSModelPytorch_2: news_vectors shape: {news_vectors.shape}\")\n",
    "        \n",
    "        scores = torch.bmm(news_vectors, user_vector.unsqueeze(-1)).squeeze(-1)\n",
    "        print(f\"NRMSModelPytorch_2: scores shape: {scores.shape}\")\n",
    "        return torch.softmax(scores, dim=-1)\n",
    "\n",
    "    def predict(self, his_input_title, pred_input_title_one):\n",
    "        print(f\"NRMSModelPytorch_2 (predict): his_input_title shape: {his_input_title.shape}, pred_input_title_one shape: {pred_input_title_one.shape}\")\n",
    "        \n",
    "        user_vector = self.user_encoder(his_input_title)\n",
    "        print(f\"NRMSModelPytorch_2 (predict): user_vector shape: {user_vector.shape}\")\n",
    "        \n",
    "        news_vector = self.news_encoder(pred_input_title_one)\n",
    "        print(f\"NRMSModelPytorch_2 (predict): news_vector shape: {news_vector.shape}\")\n",
    "        \n",
    "        prediction = torch.sigmoid(torch.dot(news_vector, user_vector))\n",
    "        print(f\"NRMSModelPytorch_2 (predict): prediction shape: {prediction.shape}\")\n",
    "        return prediction\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "class NRMSModelPytorch(nn.Module):\n",
    "    def __init__(self, hparams, word2vec_embedding=None, word_emb_dim=300, vocab_size=32000, seed=None):\n",
    "        super(NRMSModelPytorch, self).__init__()\n",
    "        self.hparams = hparams\n",
    "        self.seed = seed\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        # Initialize word embeddings\n",
    "        if word2vec_embedding is None:\n",
    "            self.word2vec_embedding = torch.randn(vocab_size, word_emb_dim)\n",
    "        else:\n",
    "            self.word2vec_embedding = torch.from_numpy(word2vec_embedding).float()\n",
    "        self.embedding_layer = nn.Embedding.from_pretrained(self.word2vec_embedding, freeze=False)\n",
    "\n",
    "        # Build model components\n",
    "        self.news_encoder = self._build_newsencoder()\n",
    "        self.user_encoder = self._build_userencoder(self.news_encoder)\n",
    "\n",
    "        # Define optimizer and loss\n",
    "        self.criterion = self._get_loss(hparams.loss)\n",
    "        self.optimizer = self._get_opt(hparams.optimizer, hparams.learning_rate)\n",
    "\n",
    "    def _get_loss(self, loss):\n",
    "        if loss == \"cross_entropy_loss\":\n",
    "            return nn.CrossEntropyLoss()\n",
    "        elif loss == \"log_loss\":\n",
    "            return nn.BCELoss()\n",
    "        else:\n",
    "            raise ValueError(f\"this loss not defined {loss}\")\n",
    "\n",
    "    def _get_opt(self, optimizer, lr):\n",
    "        if optimizer == \"adam\":\n",
    "            return optim.Adam(self.parameters(), lr=lr)\n",
    "        else:\n",
    "            raise ValueError(f\"this optimizer not defined {optimizer}\")\n",
    "\n",
    "    def _build_userencoder(self, titleencoder):\n",
    "        # Define user encoder using SelfAttention and AttLayer2 modules\n",
    "        class UserEncoder(nn.Module):\n",
    "            def __init__(self, hparams, titleencoder):\n",
    "                super(UserEncoder, self).__init__()\n",
    "                self.titleencoder = titleencoder\n",
    "                self.attention = SelfAttention_torch(hparams.head_num, hparams.head_num)\n",
    "                self.att_layer = AttLayer2_torch(hparams.attention_hidden_dim)\n",
    "\n",
    "            def forward(self, his_input_title):\n",
    "                print(\"input:\", his_input_title.shape)\n",
    "                # Encode each news in the history\n",
    "                click_title_presents = torch.stack([self.titleencoder(title) for title in his_input_title], dim=0)\n",
    "                print(\"Vlick\",click_title_presents.shape)\n",
    "                y = self.attention(click_title_presents,click_title_presents,click_title_presents)\n",
    "                print(\"y.shape\",y.shape)\n",
    "                user_present = self.att_layer(y)\n",
    "                return user_present\n",
    "\n",
    "        return UserEncoder(self.hparams, titleencoder)\n",
    "\n",
    "    def _build_newsencoder(self):\n",
    "        # Define news encoder using embedding and attention layers\n",
    "        class NewsEncoder(nn.Module):\n",
    "            def __init__(self, embedding_layer, hparams, seed):\n",
    "                super(NewsEncoder, self).__init__()\n",
    "                self.embedding = embedding_layer\n",
    "                self.dropout1 = nn.Dropout(hparams.dropout)  # Use attribute access here\n",
    "                self.attention = SelfAttention_torch(hparams.head_num, hparams.head_dim, seed=seed)\n",
    "                self.dropout2 = nn.Dropout(hparams.dropout)  # Use attribute access here\n",
    "                self.att_layer = AttLayer2_torch(hparams.attention_hidden_dim, seed=seed)\n",
    "\n",
    "\n",
    "            def forward(self, sequences_input_title):\n",
    "                # Convert input to LongTensor\n",
    "                #print(\"sequence\",sequences_input_title.shape)\n",
    "                sequences_input_title = sequences_input_title.long()\n",
    "                embedded_sequences_title = self.embedding(sequences_input_title)\n",
    "                #print(\"embedded\",embedded_sequences_title.shape)\n",
    "                y = self.dropout1(embedded_sequences_title)\n",
    "\n",
    "                y = self.attention(y,y,y)\n",
    "                y = self.dropout2(y)\n",
    "                pred_title = self.att_layer(y)\n",
    "                #print(\"pred\",pred_title.shape)\n",
    "                return pred_title\n",
    "\n",
    "        return NewsEncoder(self.embedding_layer, self.hparams, self.seed)\n",
    "\n",
    "    def forward(self, his_input_title, pred_input_title):\n",
    "        #print(his_input_title.shape)\n",
    "       # print(pred_input_title.shape)\n",
    "        user_present = self.user_encoder(his_input_title)\n",
    "        print(\"user: \", user_present.shape)\n",
    "        news_present = torch.stack([self.news_encoder(news) for news in pred_input_title], dim=0)\n",
    "        print(\"news: \", news_present.shape)\n",
    "        print(\"new user: \", user_present.unsqueeze(-1).shape)\n",
    "        preds = torch.bmm(news_present, user_present.unsqueeze(-1)).squeeze(-1)\n",
    "        print(\"npreds: \", preds.shape)\n",
    "        return torch.softmax(preds, dim=-1)\n",
    "\n",
    "    def predict(self, his_input_title, pred_input_title_one):\n",
    "        \n",
    "        user_present = self.user_encoder(his_input_title)\n",
    "        news_present_one = self.news_encoder(pred_input_title_one)\n",
    "        pred_one = torch.sigmoid(torch.dot(news_present_one, user_present))\n",
    "        return pred_one\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AttLayer2_torch(nn.Module):\n",
    "    \"\"\"Soft alignment attention implementation in PyTorch.\"\"\"\n",
    "    \n",
    "    def __init__(self, dim=200, seed=0):\n",
    "        super(AttLayer2_torch, self).__init__()\n",
    "        self.dim = dim\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "        # Initialize W, b, and q but do not specify input dimension yet\n",
    "        self.W = None\n",
    "        self.b = nn.Parameter(torch.zeros(dim))\n",
    "        self.q = nn.Parameter(torch.empty(dim, 1))\n",
    "        \n",
    "        # Initialize q using Xavier initialization\n",
    "        nn.init.xavier_uniform_(self.q)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Dynamically initialize W based on the input's feature size\n",
    "        if self.W is None:\n",
    "            input_dim = inputs.size(-1)  # Get the feature dimension of the input\n",
    "            self.W = nn.Parameter(torch.empty(input_dim, self.dim))\n",
    "            nn.init.xavier_uniform_(self.W)  # Xavier initialization for W\n",
    "        \n",
    "        # Apply soft attention mechanism\n",
    "        #print(\"input\", inputs.shape)\n",
    "        attention = torch.tanh(inputs @ self.W + self.b)\n",
    "        attention = attention @ self.q\n",
    "        #print(\"attention\", attention.shape)\n",
    "        attention = torch.squeeze(attention, dim=-1)\n",
    "        #print(\"attention2\", attention.shape)\n",
    "        \n",
    "        attention_weights = F.softmax(attention, dim=-1)\n",
    "        attention_weights = attention_weights.unsqueeze(-1)\n",
    "        #print(\"attention_weights\", attention_weights.shape)\n",
    "\n",
    "        weighted_input = inputs * attention_weights\n",
    "        return torch.sum(weighted_input, dim=1)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SelfAttention_torch(nn.Module):\n",
    "    \"\"\"Multi-head self-attention implementation in PyTorch.\"\"\"\n",
    "    \n",
    "    def __init__(self, multiheads, head_dim, seed=0, mask_right=False):\n",
    "        super(SelfAttention_torch, self).__init__()\n",
    "        self.multiheads = multiheads\n",
    "        self.head_dim = head_dim\n",
    "        self.output_dim = multiheads * head_dim\n",
    "        self.mask_right = mask_right\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "        # Initially set input_dim as None\n",
    "        self.input_dim = None\n",
    "\n",
    "        # Placeholder for the Linear layers for Q, K, V\n",
    "        self.WQ = None\n",
    "        self.WK = None\n",
    "        self.WV = None\n",
    "\n",
    "    def _mask(self, inputs, seq_len, mode=\"add\"):\n",
    "        \"\"\"Apply masking operation to inputs based on sequence length.\"\"\"\n",
    "        if seq_len is None:\n",
    "            return inputs\n",
    "        mask = (torch.arange(inputs.size(1)) < seq_len.unsqueeze(1)).float()\n",
    "        if mode == \"mul\":\n",
    "            return inputs * mask\n",
    "        elif mode == \"add\":\n",
    "            return inputs - (1 - mask) * 1e12\n",
    "\n",
    "    def forward(self, Q_seq, K_seq, V_seq, Q_len=None, V_len=None):\n",
    "        # Print input shapes before passing them to attention\n",
    "        \n",
    "        # Set input_dim dynamically based on the input shape\n",
    "        if self.input_dim is None:\n",
    "            self.input_dim = Q_seq.size(-1)  # Set input_dim from the last dimension of Q_seq\n",
    "\n",
    "            # Initialize the Linear layers with the correct input dimension\n",
    "            self.WQ = nn.Linear(self.input_dim, self.output_dim)\n",
    "            self.WK = nn.Linear(self.input_dim, self.output_dim)\n",
    "            self.WV = nn.Linear(self.input_dim, self.output_dim)\n",
    "\n",
    "        # Linear transformations for Q, K, and V\n",
    "        Q = self.WQ(Q_seq).view(-1, Q_seq.size(1), self.multiheads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        K = self.WK(K_seq).view(-1, K_seq.size(1), self.multiheads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        V = self.WV(V_seq).view(-1, V_seq.size(1), self.multiheads, self.head_dim).permute(0, 2, 1, 3)\n",
    "\n",
    "        # Scaled dot-product attention\n",
    "        A = (Q @ K.transpose(-2, -1)) / torch.sqrt(torch.tensor(self.head_dim, dtype=torch.float32))\n",
    "        if self.mask_right:\n",
    "            ones = torch.ones_like(A[0, 0])\n",
    "            mask = torch.tril(ones) * 1e12\n",
    "            A = A - mask\n",
    "\n",
    "        # Apply softmax to attention scores\n",
    "        A = F.softmax(A, dim=-1)\n",
    "\n",
    "        # Weighted sum of values\n",
    "        O = (A @ V).permute(0, 2, 1, 3).contiguous().view(-1, Q_seq.size(1), self.output_dim)\n",
    "        #print(\"atention shape: \", O.shape)\n",
    "        # Apply the mask (if applicable)\n",
    "        return self._mask(O, Q_len, \"mul\") if Q_len is not None else O\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NRMS Model Implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow as tf\n",
    "\n",
    "class hparams_nrms:\n",
    "    # INPUT DIMENTIONS:\n",
    "    title_size: int = 30\n",
    "    history_size: int = 50\n",
    "    # MODEL ARCHITECTURE\n",
    "    head_num: int = 20\n",
    "    head_dim: int = 20\n",
    "    attention_hidden_dim: int = 200\n",
    "    # MODEL OPTIMIZER:\n",
    "    optimizer: str = \"adam\"\n",
    "    loss: str = \"cross_entropy_loss\"\n",
    "    dropout: float = 0.2\n",
    "    learning_rate: float = 0.0001\n",
    "\n",
    "MODEL_NAME = \"NRMS\"\n",
    "LOG_DIR = f\"downloads/runs/{MODEL_NAME}\"\n",
    "MODEL_WEIGHTS = \"downloads/data/state_dict/NRMS/weights.weights.h5\"\n",
    "\n",
    "# CALLBACKS\n",
    "#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=LOG_DIR, histogram_freq=1)\n",
    "#early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2)\n",
    "#modelcheckpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    #filepath=MODEL_WEIGHTS, save_best_only=False, save_weights_only=True, verbose=1\n",
    "#)\n",
    "\n",
    "hparams_nrms.history_size = HISTORY_SIZE\n",
    "model = NRMSModelPytorch(\n",
    "    hparams=hparams_nrms,\n",
    "    word2vec_embedding=word2vec_embedding,\n",
    "    seed=42,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: torch.Size([64, 10, 30])\n",
      "Vlick torch.Size([64, 10, 400])\n",
      "y.shape torch.Size([64, 10, 400])\n",
      "user:  torch.Size([64, 400])\n",
      "news:  torch.Size([64, 5, 400])\n",
      "new user:  torch.Size([64, 400, 1])\n",
      "npreds:  torch.Size([64, 5])\n",
      "input: torch.Size([64, 10, 30])\n",
      "Vlick torch.Size([64, 10, 400])\n",
      "y.shape torch.Size([64, 10, 400])\n",
      "user:  torch.Size([64, 400])\n",
      "news:  torch.Size([64, 5, 400])\n",
      "new user:  torch.Size([64, 400, 1])\n",
      "npreds:  torch.Size([64, 5])\n",
      "input: torch.Size([64, 10, 30])\n",
      "Vlick torch.Size([64, 10, 400])\n",
      "y.shape torch.Size([64, 10, 400])\n",
      "user:  torch.Size([64, 400])\n",
      "news:  torch.Size([64, 5, 400])\n",
      "new user:  torch.Size([64, 400, 1])\n",
      "npreds:  torch.Size([64, 5])\n",
      "input: torch.Size([56, 10, 30])\n",
      "Vlick torch.Size([56, 10, 400])\n",
      "y.shape torch.Size([56, 10, 400])\n",
      "user:  torch.Size([56, 400])\n",
      "news:  torch.Size([56, 5, 400])\n",
      "new user:  torch.Size([56, 400, 1])\n",
      "npreds:  torch.Size([56, 5])\n",
      "Epoch 1/10, Loss: 1423.0818\n",
      "input: torch.Size([727, 10, 30])\n",
      "Vlick torch.Size([727, 10, 400])\n",
      "y.shape torch.Size([727, 10, 400])\n",
      "user:  torch.Size([727, 400])\n",
      "news:  torch.Size([727, 1, 400])\n",
      "new user:  torch.Size([727, 400, 1])\n",
      "npreds:  torch.Size([727, 1])\n",
      "input: torch.Size([738, 10, 30])\n",
      "Vlick torch.Size([738, 10, 400])\n",
      "y.shape torch.Size([738, 10, 400])\n",
      "user:  torch.Size([738, 400])\n",
      "news:  torch.Size([738, 1, 400])\n",
      "new user:  torch.Size([738, 400, 1])\n",
      "npreds:  torch.Size([738, 1])\n",
      "input: torch.Size([814, 10, 30])\n",
      "Vlick torch.Size([814, 10, 400])\n",
      "y.shape torch.Size([814, 10, 400])\n",
      "user:  torch.Size([814, 400])\n",
      "news:  torch.Size([814, 1, 400])\n",
      "new user:  torch.Size([814, 400, 1])\n",
      "npreds:  torch.Size([814, 1])\n",
      "input: torch.Size([672, 10, 30])\n",
      "Vlick torch.Size([672, 10, 400])\n",
      "y.shape torch.Size([672, 10, 400])\n",
      "user:  torch.Size([672, 400])\n",
      "news:  torch.Size([672, 1, 400])\n",
      "new user:  torch.Size([672, 400, 1])\n",
      "npreds:  torch.Size([672, 1])\n",
      "Validation Loss: 0.0000\n",
      "input: torch.Size([64, 10, 30])\n",
      "Vlick torch.Size([64, 10, 400])\n",
      "y.shape torch.Size([64, 10, 400])\n",
      "user:  torch.Size([64, 400])\n",
      "news:  torch.Size([64, 5, 400])\n",
      "new user:  torch.Size([64, 400, 1])\n",
      "npreds:  torch.Size([64, 5])\n",
      "input: torch.Size([64, 10, 30])\n",
      "Vlick torch.Size([64, 10, 400])\n",
      "y.shape torch.Size([64, 10, 400])\n",
      "user:  torch.Size([64, 400])\n",
      "news:  torch.Size([64, 5, 400])\n",
      "new user:  torch.Size([64, 400, 1])\n",
      "npreds:  torch.Size([64, 5])\n",
      "input: torch.Size([64, 10, 30])\n",
      "Vlick torch.Size([64, 10, 400])\n",
      "y.shape torch.Size([64, 10, 400])\n",
      "user:  torch.Size([64, 400])\n",
      "news:  torch.Size([64, 5, 400])\n",
      "new user:  torch.Size([64, 400, 1])\n",
      "npreds:  torch.Size([64, 5])\n",
      "input: torch.Size([56, 10, 30])\n",
      "Vlick torch.Size([56, 10, 400])\n",
      "y.shape torch.Size([56, 10, 400])\n",
      "user:  torch.Size([56, 400])\n",
      "news:  torch.Size([56, 5, 400])\n",
      "new user:  torch.Size([56, 400, 1])\n",
      "npreds:  torch.Size([56, 5])\n",
      "Epoch 2/10, Loss: 1422.9812\n",
      "input: torch.Size([727, 10, 30])\n",
      "Vlick torch.Size([727, 10, 400])\n",
      "y.shape torch.Size([727, 10, 400])\n",
      "user:  torch.Size([727, 400])\n",
      "news:  torch.Size([727, 1, 400])\n",
      "new user:  torch.Size([727, 400, 1])\n",
      "npreds:  torch.Size([727, 1])\n",
      "input: torch.Size([738, 10, 30])\n",
      "Vlick torch.Size([738, 10, 400])\n",
      "y.shape torch.Size([738, 10, 400])\n",
      "user:  torch.Size([738, 400])\n",
      "news:  torch.Size([738, 1, 400])\n",
      "new user:  torch.Size([738, 400, 1])\n",
      "npreds:  torch.Size([738, 1])\n",
      "input: torch.Size([814, 10, 30])\n",
      "Vlick torch.Size([814, 10, 400])\n",
      "y.shape torch.Size([814, 10, 400])\n",
      "user:  torch.Size([814, 400])\n",
      "news:  torch.Size([814, 1, 400])\n",
      "new user:  torch.Size([814, 400, 1])\n",
      "npreds:  torch.Size([814, 1])\n",
      "input: torch.Size([672, 10, 30])\n",
      "Vlick torch.Size([672, 10, 400])\n",
      "y.shape torch.Size([672, 10, 400])\n",
      "user:  torch.Size([672, 400])\n",
      "news:  torch.Size([672, 1, 400])\n",
      "new user:  torch.Size([672, 400, 1])\n",
      "npreds:  torch.Size([672, 1])\n",
      "Validation Loss: 0.0000\n",
      "input: torch.Size([64, 10, 30])\n",
      "Vlick torch.Size([64, 10, 400])\n",
      "y.shape torch.Size([64, 10, 400])\n",
      "user:  torch.Size([64, 400])\n",
      "news:  torch.Size([64, 5, 400])\n",
      "new user:  torch.Size([64, 400, 1])\n",
      "npreds:  torch.Size([64, 5])\n",
      "input: torch.Size([64, 10, 30])\n",
      "Vlick torch.Size([64, 10, 400])\n",
      "y.shape torch.Size([64, 10, 400])\n",
      "user:  torch.Size([64, 400])\n",
      "news:  torch.Size([64, 5, 400])\n",
      "new user:  torch.Size([64, 400, 1])\n",
      "npreds:  torch.Size([64, 5])\n",
      "input: torch.Size([64, 10, 30])\n",
      "Vlick torch.Size([64, 10, 400])\n",
      "y.shape torch.Size([64, 10, 400])\n",
      "user:  torch.Size([64, 400])\n",
      "news:  torch.Size([64, 5, 400])\n",
      "new user:  torch.Size([64, 400, 1])\n",
      "npreds:  torch.Size([64, 5])\n",
      "input: torch.Size([56, 10, 30])\n",
      "Vlick torch.Size([56, 10, 400])\n",
      "y.shape torch.Size([56, 10, 400])\n",
      "user:  torch.Size([56, 400])\n",
      "news:  torch.Size([56, 5, 400])\n",
      "new user:  torch.Size([56, 400, 1])\n",
      "npreds:  torch.Size([56, 5])\n",
      "Epoch 3/10, Loss: 1422.8469\n",
      "input: torch.Size([727, 10, 30])\n",
      "Vlick torch.Size([727, 10, 400])\n",
      "y.shape torch.Size([727, 10, 400])\n",
      "user:  torch.Size([727, 400])\n",
      "news:  torch.Size([727, 1, 400])\n",
      "new user:  torch.Size([727, 400, 1])\n",
      "npreds:  torch.Size([727, 1])\n",
      "input: torch.Size([738, 10, 30])\n",
      "Vlick torch.Size([738, 10, 400])\n",
      "y.shape torch.Size([738, 10, 400])\n",
      "user:  torch.Size([738, 400])\n",
      "news:  torch.Size([738, 1, 400])\n",
      "new user:  torch.Size([738, 400, 1])\n",
      "npreds:  torch.Size([738, 1])\n",
      "input: torch.Size([814, 10, 30])\n",
      "Vlick torch.Size([814, 10, 400])\n",
      "y.shape torch.Size([814, 10, 400])\n",
      "user:  torch.Size([814, 400])\n",
      "news:  torch.Size([814, 1, 400])\n",
      "new user:  torch.Size([814, 400, 1])\n",
      "npreds:  torch.Size([814, 1])\n",
      "input: torch.Size([672, 10, 30])\n",
      "Vlick torch.Size([672, 10, 400])\n",
      "y.shape torch.Size([672, 10, 400])\n",
      "user:  torch.Size([672, 400])\n",
      "news:  torch.Size([672, 1, 400])\n",
      "new user:  torch.Size([672, 400, 1])\n",
      "npreds:  torch.Size([672, 1])\n",
      "Validation Loss: 0.0000\n",
      "input: torch.Size([64, 10, 30])\n",
      "Vlick torch.Size([64, 10, 400])\n",
      "y.shape torch.Size([64, 10, 400])\n",
      "user:  torch.Size([64, 400])\n",
      "news:  torch.Size([64, 5, 400])\n",
      "new user:  torch.Size([64, 400, 1])\n",
      "npreds:  torch.Size([64, 5])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m# Backward pass and optimize\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 45\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Validation loop\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 140\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/optim/optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/optim/adam.py:234\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`requires_grad` is not supported for `step` in differentiable mode\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    232\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 234\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m         \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m         \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m         \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m         \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m         \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m         \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m         \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m         \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/optim/adam.py:300\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 300\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/optim/adam.py:363\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    360\u001b[0m     param \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mview_as_real(param)\n\u001b[1;32m    362\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m \u001b[43mexp_avg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39madd_(grad, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[1;32m    364\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad\u001b[38;5;241m.\u001b[39mconj(), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Move the model to the appropriate device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define your dataloaders (ensure they are instances of PyTorch DataLoader)\n",
    "train_dataloader = train_pytorch_dataset  # Created using NRMSDataLoader\n",
    "val_dataloader =val_pytorch_dataset      # Created using NRMSDataLoader\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    total_loss = 0\n",
    "    \n",
    "    for (his_input_title, pred_input_title), labels in train_dataloader:\n",
    "        # Convert numpy arrays to PyTorch tensors and move to the appropriate device\n",
    "        his_input_title = torch.tensor(his_input_title).to(device)\n",
    "        pred_input_title = torch.tensor(pred_input_title).to(device)\n",
    "        labels = torch.tensor(labels).to(device)\n",
    "        #print(\"______________________________________________________\")\n",
    "        #print(\"User history input: \", his_input_title.shape)\n",
    "        #print(\"News Items: \", pred_input_title.shape)\n",
    "        #print(\"Target: \", labels.shape)\n",
    "        \n",
    "        # Zero the gradients\n",
    "        model.optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        predictions = model(his_input_title, pred_input_title)\n",
    "        #print(\"Predictions: \", predictions.shape)\n",
    "\n",
    "        # Reshape labels to match predictions batch size\n",
    "        labels = labels.view(-1)  # Flatten the labels to match batch size (flatten into a vector)\n",
    "        \n",
    "        # Ensure predictions have the shape [batch_size, num_classes]\n",
    "        predictions = predictions.view(-1)  # Flatten predictions as necessary\n",
    "        #print(\"Predictions: \", predictions.shape)\n",
    "        #print(labels.shape)\n",
    "        # Compute loss\n",
    "        loss = model.criterion(predictions, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        model.optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        for (his_input_title, pred_input_title), labels in val_dataloader:\n",
    "            # Move tensors to the appropriate device\n",
    "            # Convert numpy arrays to PyTorch tensors and move to the appropriate device\n",
    "            his_input_title = torch.tensor(his_input_title).to(device)\n",
    "            pred_input_title = torch.tensor(pred_input_title).to(device)\n",
    "            labels = torch.tensor(labels).to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            predictions = model(his_input_title, pred_input_title)\n",
    "\n",
    "            labels = labels.view(-1)  # Flatten the labels to match batch size (flatten into a vector)\n",
    "        \n",
    "            # Ensure predictions have the shape [batch_size, num_classes]\n",
    "            predictions = predictions.view(-1)  # Flatten predictions as necessary\n",
    "            #print(\"Predictions: \", predictions.shape)\n",
    "            #print(labels.shape)\n",
    "            # Compute loss\n",
    "            loss = model.criterion(predictions, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average AUC Score: 0.5\n"
     ]
    }
   ],
   "source": [
    "auc_metric = AucScore()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_true_total = []\n",
    "    y_pred_total = []\n",
    "    for (his_input_title, pred_input_title), labels in val_dataloader:\n",
    "        # Move tensors to the appropriate device\n",
    "        # Convert numpy arrays to PyTorch tensors and move to the appropriate device\n",
    "        his_input_title = torch.tensor(his_input_title).to(device)\n",
    "        pred_input_title = torch.tensor(pred_input_title).to(device)\n",
    "        labels = torch.tensor(labels).to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        predictions = model(his_input_title, pred_input_title)\n",
    "\n",
    "        labels = labels.view(-1)  # Flatten the labels to match batch size (flatten into a vector)\n",
    "            \n",
    "        # Ensure predictions have the shape [batch_size, num_classes]\n",
    "        predictions = predictions.view(-1)\n",
    "        \n",
    "        y_pred_total.append( predictions.numpy() )\n",
    "        y_true_total.append( labels.numpy() )\n",
    "\n",
    "        \n",
    "    auc_value = auc_metric.calculate(y_true_total, y_pred_total)\n",
    "    print(\"Average AUC Score:\", auc_value)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NRMSModelPytorch' object has no attribute 'scorer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pred_validation \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(val_dataloader)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1269\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1268\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1269\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NRMSModelPytorch' object has no attribute 'scorer'"
     ]
    }
   ],
   "source": [
    "pred_validation = model.scorer.predict(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user_id', 'article_id_fixed', 'article_ids_inview', 'article_ids_clicked', 'impression_id', 'labels']\n"
     ]
    }
   ],
   "source": [
    "print(df_validation.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_validation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_validation \u001b[38;5;241m=\u001b[39m add_prediction_scores(df_validation, \u001b[43mpred_validation\u001b[49m\u001b[38;5;241m.\u001b[39mtolist())\u001b[38;5;241m.\u001b[39mpipe(\n\u001b[1;32m      2\u001b[0m     add_known_user_column, known_users\u001b[38;5;241m=\u001b[39mdf_train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      3\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred_validation' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "df_validation = add_prediction_scores(df_validation, pred_validation.tolist()).pipe(\n",
    "    add_known_user_column, known_users=df_train[\"user_id\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "ColumnNotFoundError",
     "evalue": "\"scores\" not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mColumnNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m metrics \u001b[38;5;241m=\u001b[39m MetricEvaluator(\n\u001b[1;32m      2\u001b[0m     labels\u001b[38;5;241m=\u001b[39mdf_validation[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto_list(),\n\u001b[0;32m----> 3\u001b[0m     predictions\u001b[38;5;241m=\u001b[39m\u001b[43mdf_validation\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscores\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mto_list(),\n\u001b[1;32m      4\u001b[0m     metric_functions\u001b[38;5;241m=\u001b[39m[AucScore(), MrrScore(), NdcgScore(k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m), NdcgScore(k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)],\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m metrics\u001b[38;5;241m.\u001b[39mevaluate()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#MetricEvaluator class>: \u001b[39;00m\n\u001b[1;32m     11\u001b[0m  \u001b[38;5;66;03m#{\u001b[39;00m\n\u001b[1;32m     12\u001b[0m    \u001b[38;5;66;03m## \"auc\": 0.5276161100402653,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m \n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#Baseline DEMO:\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/polars/dataframe/frame.py:1353\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\n\u001b[1;32m   1217\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1218\u001b[0m     key: (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1227\u001b[0m     ),\n\u001b[1;32m   1228\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series \u001b[38;5;241m|\u001b[39m Any:\n\u001b[1;32m   1229\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1230\u001b[0m \u001b[38;5;124;03m    Get part of the DataFrame as a new DataFrame, Series, or scalar.\u001b[39;00m\n\u001b[1;32m   1231\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1351\u001b[0m \u001b[38;5;124;03m    └─────┴─────┴─────┘\u001b[39;00m\n\u001b[1;32m   1352\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_df_item_by_key\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/polars/_utils/getitem.py:163\u001b[0m, in \u001b[0;36mget_df_item_by_key\u001b[0;34m(df, key)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# Single string input, e.g. df[\"a\"]\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# This case is required because empty strings are otherwise treated\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# as an empty Sequence in `_select_rows`\u001b[39;00m\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# Single input - df[1] - or multiple inputs - df[\"a\", \"b\", \"c\"]\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/polars/dataframe/frame.py:7908\u001b[0m, in \u001b[0;36mDataFrame.get_column\u001b[0;34m(self, name, default)\u001b[0m\n\u001b[1;32m   7861\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   7862\u001b[0m \u001b[38;5;124;03mGet a single column by name.\u001b[39;00m\n\u001b[1;32m   7863\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   7905\u001b[0m \u001b[38;5;124;03mTrue\u001b[39;00m\n\u001b[1;32m   7906\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   7907\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 7908\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m wrap_s(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   7909\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ColumnNotFoundError:\n\u001b[1;32m   7910\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m default \u001b[38;5;129;01mis\u001b[39;00m no_default:\n",
      "\u001b[0;31mColumnNotFoundError\u001b[0m: \"scores\" not found"
     ]
    }
   ],
   "source": [
    "metrics = MetricEvaluator(\n",
    "    labels=df_validation[\"labels\"].to_list(),\n",
    "    predictions=df_validation[\"scores\"].to_list(),\n",
    "    metric_functions=[AucScore(), MrrScore(), NdcgScore(k=5), NdcgScore(k=10)],\n",
    ")\n",
    "metrics.evaluate()\n",
    "\n",
    "\n",
    "\n",
    "#MetricEvaluator class>: \n",
    " #{\n",
    "   ## \"auc\": 0.5276161100402653,\n",
    "   # \"mrr\": 0.32824818639682796,\n",
    "#\"ndcg@5\": 0.3633463986420684,\n",
    "   # \"ndcg@10\": 0.44525616791861783\n",
    "#}\n",
    "\n",
    "#Baseline DEMO:\n",
    "\"\"\"\n",
    "<MetricEvaluator class>: \n",
    " {\n",
    "    \"auc\": 0.5015856923908388,\n",
    "    \"mrr\": 0.2982510114798958,\n",
    "    \"ndcg@5\": 0.337370835795743,\n",
    "    \"ndcg@10\": 0.4112965077837971\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
