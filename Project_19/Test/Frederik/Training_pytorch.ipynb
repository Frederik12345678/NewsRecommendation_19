{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.ticker as mticker\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import polars as pl # used to read the .parquet files so its important\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Add the parent directory (or specify path to 'utils' if it's higher)\n",
    "dir = os.path.abspath(os.path.join(os.getcwd(), '..', '..')) \n",
    "sys.path.append(dir)\n",
    "\n",
    "from dataloader.NRMSdataloader import NRMSDataLoader\n",
    "from models.nrms import NRMSModelPytorch\n",
    "from eval.metricEval import MetricEvaluator, AucScore, MrrScore, NdcgScore\n",
    "\n",
    "# Now you can import from utils\n",
    "from utils import add_known_user_column, add_prediction_scores\n",
    "from utils import get_transformers_word_embeddings, concat_str_columns,convert_text2encoding_with_transformers, create_article_id_to_value_mapping\n",
    "from utils import get_script_directory, slice_join_dataframes, truncate_history,sampling_strategy_wu2019, create_binary_labels_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_path = get_script_directory()\n",
    "\n",
    "DEFAULT_IS_BEYOND_ACCURACY_COL = \"is_beyond_accuracy\"\n",
    "\n",
    "\n",
    "PATH = Path(basic_path+\"/Data\")\n",
    "TRAIN_VAL_SPLIT = f\"ebnerd_demo\"  # [ebnerd_demo, ebnerd_small, ebnerd_large]\n",
    "TEST_SPLIT = f\"ebnerd_testset\"  # \"ebnerd_testset\", \"ebnerd_testset_gt\"\n",
    "\n",
    "#_____________________Training____________________________\n",
    "# Reads the behaviors file from training data\n",
    "df_behaviors_train = df_behaviors = pl.scan_parquet(\n",
    "    PATH.joinpath(TRAIN_VAL_SPLIT, \"train\", \"behaviors.parquet\")\n",
    ")\n",
    "# Reads the history file from training data\n",
    "df_history_train = df_behaviors = pl.scan_parquet(\n",
    "    PATH.joinpath(TRAIN_VAL_SPLIT, \"train\", \"history.parquet\")\n",
    ")\n",
    "\n",
    "#_____________________Validation____________________________\n",
    "# Reads the behaviors file from Validation data\n",
    "df_behaviors_val = df_behaviors = pl.scan_parquet(\n",
    "    PATH.joinpath(TRAIN_VAL_SPLIT, \"validation\", \"behaviors.parquet\")\n",
    ")\n",
    "# Reads the History file from Validation data\n",
    "df_history_val = df_behaviors = pl.scan_parquet(\n",
    "    PATH.joinpath(TRAIN_VAL_SPLIT, \"validation\", \"history.parquet\")\n",
    ")\n",
    "\n",
    "#_____________________Test____________________________\n",
    "# Reads the behaviors file from test data\n",
    "df_behaviors_test = df_behaviors = (\n",
    "    pl.scan_parquet(PATH.joinpath(TEST_SPLIT, \"test\", \"behaviors.parquet\"))\n",
    "    .filter(~pl.col(DEFAULT_IS_BEYOND_ACCURACY_COL))\n",
    "    .drop(DEFAULT_IS_BEYOND_ACCURACY_COL)\n",
    ")\n",
    "# Reads the History file from test data\n",
    "df_history_test = df_behaviors = pl.scan_parquet(\n",
    "    PATH.joinpath(TEST_SPLIT, \"test\", \"history.parquet\")\n",
    ")\n",
    "\n",
    "# ?? seem we already read this file ? but now without .drop(DEFAULT_IS_BEYOND_ACCURACY_COL)\n",
    "df_behaviors_test_ba = df_behaviors = pl.scan_parquet(\n",
    "    PATH.joinpath(TEST_SPLIT, \"test\", \"behaviors.parquet\")\n",
    ").filter(pl.col(DEFAULT_IS_BEYOND_ACCURACY_COL))\n",
    "\n",
    "#_____________________Reads Articles ??____________________________\n",
    "df_articles = pl.scan_parquet(PATH.joinpath(TEST_SPLIT,\"articles.parquet\")).collect()\n",
    "\n",
    "PLOT_PATH = Path(\"plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom src.ebrec.utils._constants import (\\n    DEFAULT_HISTORY_ARTICLE_ID_COL, = f\"{\"article_id\"}_fixed\"\\n    DEFAULT_CLICKED_ARTICLES_COL, = \"article_ids_clicked\"\\n    DEFAULT_INVIEW_ARTICLES_COL, = \"article_ids_inview\"\\n    DEFAULT_IMPRESSION_ID_COL, = \"impression_id\"\\n    DEFAULT_SUBTITLE_COL, = \"subtitle\"\\n    DEFAULT_LABELS_COL, = \"labels\"\\n    DEFAULT_TITLE_COL, =  \"title\"\\n    DEFAULT_USER_COL, = \"user_id\"\\n)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "from src.ebrec.utils._constants import (\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL, = f\"{\"article_id\"}_fixed\"\n",
    "    DEFAULT_CLICKED_ARTICLES_COL, = \"article_ids_clicked\"\n",
    "    DEFAULT_INVIEW_ARTICLES_COL, = \"article_ids_inview\"\n",
    "    DEFAULT_IMPRESSION_ID_COL, = \"impression_id\"\n",
    "    DEFAULT_SUBTITLE_COL, = \"subtitle\"\n",
    "    DEFAULT_LABELS_COL, = \"labels\"\n",
    "    DEFAULT_TITLE_COL, =  \"title\"\n",
    "    DEFAULT_USER_COL, = \"user_id\"\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ebnerd_from_path(path: Path, history_size: int = 30) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Load ebnerd - function\n",
    "    \"\"\"\n",
    "    df_history = (\n",
    "        pl.scan_parquet(path.joinpath(\"history.parquet\"))\n",
    "        .select(\"user_id\", \"article_id_fixed\")\n",
    "        .pipe(\n",
    "            truncate_history,\n",
    "            column=\"article_id_fixed\",\n",
    "            history_size=history_size,\n",
    "            padding_value=0,\n",
    "            enable_warning=False,\n",
    "        )\n",
    "    )\n",
    "    df_behaviors = (\n",
    "        pl.scan_parquet(path.joinpath(\"behaviors.parquet\"))\n",
    "        .collect()\n",
    "        .pipe(\n",
    "            slice_join_dataframes,\n",
    "            df2=df_history.collect(),\n",
    "            on=\"user_id\",\n",
    "            how=\"left\",\n",
    "        )\n",
    "    )\n",
    "    return df_behaviors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_path = get_script_directory()\n",
    "\n",
    "PATH = Path(basic_path+\"/Data\")\n",
    "DATASPLIT = f\"ebnerd_demo\"  # [ebnerd_demo, ebnerd_small, ebnerd_large]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>article_id_fixed</th><th>article_ids_inview</th><th>article_ids_clicked</th><th>impression_id</th><th>labels</th></tr><tr><td>u32</td><td>list[i32]</td><td>list[i64]</td><td>list[i64]</td><td>u32</td><td>list[i8]</td></tr></thead><tbody><tr><td>287386</td><td>[9768764, 9768802, … 9769197]</td><td>[9695098, 9776190, … 9775965]</td><td>[9775965]</td><td>564824097</td><td>[0, 0, … 1]</td></tr><tr><td>463733</td><td>[9769575, 9770594, … 9767697]</td><td>[9775733, 9775733, … 9775388]</td><td>[9775388]</td><td>393207321</td><td>[0, 0, … 1]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 6)\n",
       "┌─────────┬───────────────────┬───────────────────┬──────────────────┬───────────────┬─────────────┐\n",
       "│ user_id ┆ article_id_fixed  ┆ article_ids_invie ┆ article_ids_clic ┆ impression_id ┆ labels      │\n",
       "│ ---     ┆ ---               ┆ w                 ┆ ked              ┆ ---           ┆ ---         │\n",
       "│ u32     ┆ list[i32]         ┆ ---               ┆ ---              ┆ u32           ┆ list[i8]    │\n",
       "│         ┆                   ┆ list[i64]         ┆ list[i64]        ┆               ┆             │\n",
       "╞═════════╪═══════════════════╪═══════════════════╪══════════════════╪═══════════════╪═════════════╡\n",
       "│ 287386  ┆ [9768764,         ┆ [9695098,         ┆ [9775965]        ┆ 564824097     ┆ [0, 0, … 1] │\n",
       "│         ┆ 9768802, …        ┆ 9776190, …        ┆                  ┆               ┆             │\n",
       "│         ┆ 9769197]          ┆ 9775965]          ┆                  ┆               ┆             │\n",
       "│ 463733  ┆ [9769575,         ┆ [9775733,         ┆ [9775388]        ┆ 393207321     ┆ [0, 0, … 1] │\n",
       "│         ┆ 9770594, …        ┆ 9775733, …        ┆                  ┆               ┆             │\n",
       "│         ┆ 9767697]          ┆ 9775388]          ┆                  ┆               ┆             │\n",
       "└─────────┴───────────────────┴───────────────────┴──────────────────┴───────────────┴─────────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COLUMNS = [\n",
    "    \"user_id\",\n",
    "    \"article_id_fixed\",\n",
    "    \"article_ids_inview\",\n",
    "    \"article_ids_clicked\",\n",
    "    \"impression_id\",\n",
    "]\n",
    "HISTORY_SIZE = 10\n",
    "FRACTION = 0.01\n",
    "\n",
    "df_train = (\n",
    "    ebnerd_from_path(PATH.joinpath(DATASPLIT, \"train\"), history_size=HISTORY_SIZE)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(\n",
    "        sampling_strategy_wu2019,\n",
    "        npratio=4,\n",
    "        shuffle=True,\n",
    "        with_replacement=True,\n",
    "        seed=123,\n",
    "    )\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION)\n",
    ")\n",
    "# =>\n",
    "df_validation = (\n",
    "    ebnerd_from_path(PATH.joinpath(DATASPLIT, \"validation\"), history_size=HISTORY_SIZE)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION)\n",
    ")\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 21)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>article_id</th><th>title</th><th>subtitle</th><th>last_modified_time</th><th>premium</th><th>body</th><th>published_time</th><th>image_ids</th><th>article_type</th><th>url</th><th>ner_clusters</th><th>entity_groups</th><th>topics</th><th>category</th><th>subcategory</th><th>category_str</th><th>total_inviews</th><th>total_pageviews</th><th>total_read_time</th><th>sentiment_score</th><th>sentiment_label</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>datetime[μs]</td><td>bool</td><td>str</td><td>datetime[μs]</td><td>list[i64]</td><td>str</td><td>str</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>i16</td><td>list[i16]</td><td>str</td><td>i32</td><td>i32</td><td>f32</td><td>f32</td><td>str</td></tr></thead><tbody><tr><td>3037230</td><td>&quot;Ishockey-spiller: Jeg troede j…</td><td>&quot;ISHOCKEY: Ishockey-spilleren S…</td><td>2023-06-29 06:20:57</td><td>false</td><td>&quot;Ambitionerne om at komme til U…</td><td>2003-08-28 08:55:00</td><td>null</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/sport/…</td><td>[]</td><td>[]</td><td>[&quot;Kriminalitet&quot;, &quot;Kendt&quot;, … &quot;Mindre ulykke&quot;]</td><td>142</td><td>[327, 334]</td><td>&quot;sport&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9752</td><td>&quot;Negative&quot;</td></tr><tr><td>3044020</td><td>&quot;Prins Harry tvunget til dna-te…</td><td>&quot;Hoffet tvang Prins Harry til a…</td><td>2023-06-29 06:21:16</td><td>false</td><td>&quot;Den britiske tabloidavis The S…</td><td>2005-06-29 08:47:00</td><td>[3097307, 3097197, 3104927]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/underh…</td><td>[&quot;Harry&quot;, &quot;James Hewitt&quot;]</td><td>[&quot;PER&quot;, &quot;PER&quot;]</td><td>[&quot;Kriminalitet&quot;, &quot;Kendt&quot;, … &quot;Personfarlig kriminalitet&quot;]</td><td>414</td><td>[432]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.7084</td><td>&quot;Negative&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 21)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ article_i ┆ title     ┆ subtitle  ┆ last_modi ┆ … ┆ total_pag ┆ total_rea ┆ sentiment ┆ sentimen │\n",
       "│ d         ┆ ---       ┆ ---       ┆ fied_time ┆   ┆ eviews    ┆ d_time    ┆ _score    ┆ t_label  │\n",
       "│ ---       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ i32       ┆           ┆           ┆ datetime[ ┆   ┆ i32       ┆ f32       ┆ f32       ┆ str      │\n",
       "│           ┆           ┆           ┆ μs]       ┆   ┆           ┆           ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 3037230   ┆ Ishockey- ┆ ISHOCKEY: ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9752    ┆ Negative │\n",
       "│           ┆ spiller:  ┆ Ishockey- ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Jeg       ┆ spilleren ┆ 06:20:57  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ troede j… ┆ S…        ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3044020   ┆ Prins     ┆ Hoffet    ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.7084    ┆ Negative │\n",
       "│           ┆ Harry     ┆ tvang     ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ tvunget   ┆ Prins     ┆ 06:21:16  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ til       ┆ Harry til ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ dna-te…   ┆ a…        ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles = pl.read_parquet(PATH.joinpath(DATASPLIT,\"articles.parquet\"))\n",
    "df_articles.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORMER_MODEL_NAME = \"FacebookAI/xlm-roberta-base\"\n",
    "TEXT_COLUMNS_TO_USE = [\"subtitle\", \"title\"]\n",
    "MAX_TITLE_LENGTH = 30\n",
    "\n",
    "# LOAD HUGGINGFACE:\n",
    "transformer_model = AutoModel.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "transformer_tokenizer = AutoTokenizer.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "\n",
    "# We'll init the word embeddings using the\n",
    "word2vec_embedding = get_transformers_word_embeddings(transformer_model)\n",
    "#\n",
    "df_articles, cat_cal = concat_str_columns(df_articles, columns=TEXT_COLUMNS_TO_USE)\n",
    "df_articles, token_col_title = convert_text2encoding_with_transformers(\n",
    "    df_articles, transformer_tokenizer, cat_cal, max_length=MAX_TITLE_LENGTH\n",
    ")\n",
    "# =>\n",
    "article_mapping = create_article_id_to_value_mapping(\n",
    "    df=df_articles, value_col=token_col_title\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from typing import Any\n",
    "\n",
    "# Assuming `NRMSDataLoader` is the class you provided above\n",
    "\n",
    "class PyTorchNRMSDataLoader(Dataset):\n",
    "    def __init__(self, tf_dataloader: NRMSDataLoader):\n",
    "        \"\"\"\n",
    "        Wraps the TensorFlow DataLoader to work with PyTorch.\n",
    "        \n",
    "        Args:\n",
    "        - tf_dataloader: An instance of the NRMSDataLoader.\n",
    "        \"\"\"\n",
    "        self.tf_dataloader = tf_dataloader\n",
    "    \n",
    "    def __len__(self):\n",
    "        # The length of the PyTorch Dataset is the same as the number of batches in TensorFlow's DataLoader\n",
    "        return len(self.tf_dataloader)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> tuple:\n",
    "        \"\"\"\n",
    "        Fetches a batch of data from the TensorFlow DataLoader and converts it to PyTorch format.\n",
    "        \n",
    "        Args:\n",
    "        - idx: The index of the batch.\n",
    "        \n",
    "        Returns:\n",
    "        - A tuple of (his_input_title, pred_input_title) and batch_y as PyTorch tensors.\n",
    "        \"\"\"\n",
    "        # Get the batch from the TensorFlow DataLoader\n",
    "        (his_input_title, pred_input_title), batch_y = self.tf_dataloader[idx]\n",
    "        \n",
    "        # Convert numpy arrays to PyTorch tensors\n",
    "        his_input_title = torch.tensor(his_input_title, dtype=torch.float32)\n",
    "        pred_input_title = torch.tensor(pred_input_title, dtype=torch.float32)\n",
    "        batch_y = torch.tensor(batch_y, dtype=torch.float32)\n",
    "        \n",
    "        return (his_input_title, pred_input_title), batch_y\n",
    "\n",
    "\n",
    "# Initialize your TensorFlow-based NRMSDataLoader (as shown in your example)\n",
    "train_dataloader = NRMSDataLoader(\n",
    "    behaviors=df_train,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=\"article_id_fixed\",\n",
    "    eval_mode=False,\n",
    "    batch_size=64,\n",
    ")\n",
    "\n",
    "val_dataloader = NRMSDataLoader(\n",
    "    behaviors=df_validation,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=\"article_id_fixed\",\n",
    "    eval_mode=True,\n",
    "    batch_size=64,\n",
    ")\n",
    "\n",
    "# Wrap the TensorFlow DataLoader into a PyTorch Dataset\n",
    "train_pytorch_dataset = PyTorchNRMSDataLoader(train_dataloader)\n",
    "val_pytorch_dataset = PyTorchNRMSDataLoader(val_dataloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10, 30])\n",
      "torch.Size([64, 5, 30])\n",
      "torch.Size([64, 10, 30])\n",
      "torch.Size([64, 5, 30])\n",
      "torch.Size([64, 10, 30])\n",
      "torch.Size([64, 5, 30])\n",
      "torch.Size([56, 10, 30])\n",
      "torch.Size([56, 5, 30])\n",
      "torch.Size([717, 10, 30])\n",
      "torch.Size([838, 10, 30])\n",
      "torch.Size([655, 10, 30])\n",
      "torch.Size([770, 10, 30])\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# Now you can use these DataLoader objects with your PyTorch model\n",
    "for (his_input_title, pred_input_title), batch_y in train_pytorch_dataset:\n",
    "    print(his_input_title.shape)\n",
    "    print(pred_input_title.shape)\n",
    "\n",
    "for (his_input_title, pred_input_title), batch_y in val_pytorch_dataset:\n",
    "    print(his_input_title.shape)\n",
    "\n",
    "print(len(train_pytorch_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    d_k = query.size(-1)\n",
    "    print(f\"Attention: query shape: {query.shape}, key shape: {key.shape}, value shape: {value.shape}\")\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "    print(f\"Attention: scores shape: {scores.shape}\")\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -math.inf)\n",
    "    p_attn = F.softmax(scores, dim = -1)\n",
    "    print(f\"Attention: p_attn shape: {p_attn.shape}\")\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    output = torch.matmul(p_attn, value)\n",
    "    print(f\"Attention: output shape: {output.shape}\")\n",
    "    return output, p_attn\n",
    "\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    \"\"\"A simple Multi-head attention layer.\"\"\"\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model*h\n",
    "        print(\"d_k\", self.d_k)\n",
    "        print(\"d_model\",d_model)\n",
    "        print(\"h\",h)\n",
    "        self.h = h\n",
    "        self.linears = nn.ModuleList([nn.Linear(768, self.d_k) for _ in range(4)])\n",
    "        self.attn = None # store the attention maps\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        nbatches = query.size(0)\n",
    "        print(f\"MultiHeadedAttention: input query shape: {query.shape}, key shape: {key.shape}, value shape: {value.shape}\")\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "\n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k \n",
    "        \n",
    "        query, key, value = [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2) for l, x in zip(self.linears, (query, key, value))]\n",
    "        print(f\"MultiHeadedAttention: reshaped query shape: {query.shape}, key shape: {key.shape}, value shape: {value.shape}\")\n",
    "\n",
    "        # 2) Apply attention on all the projected vectors in batch. \n",
    "        x, self.attn = attention(query, key, value, mask=mask, dropout=self.dropout)\n",
    "        print(f\"MultiHeadedAttention: attention output shape: {x.shape}\")\n",
    "\n",
    "        # 3) \"Concat\" using a view and apply a final linear. \n",
    "        x = x.transpose(1, 2).contiguous().view(nbatches, -1, self.h * self.d_k)\n",
    "        print(f\"MultiHeadedAttention: concatenated output shape: {x.shape}\")\n",
    "        return self.linears[-1](x)\n",
    "\n",
    "class AttLayer2_torch(nn.Module):\n",
    "    \"\"\"Soft alignment attention implementation in PyTorch.\"\"\"\n",
    "    \n",
    "    def __init__(self, dim=200, seed=0):\n",
    "        super(AttLayer2_torch, self).__init__()\n",
    "        self.dim = dim\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "        # Initialize W, b, and q but do not specify input dimension yet\n",
    "        self.W = None\n",
    "        self.b = nn.Parameter(torch.zeros(dim))\n",
    "        self.q = nn.Parameter(torch.empty(dim, 1))\n",
    "        \n",
    "        # Initialize q using Xavier initialization\n",
    "        nn.init.xavier_uniform_(self.q)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Dynamically initialize W based on the input's feature size\n",
    "        if self.W is None:\n",
    "            input_dim = inputs.size(-1)  # Get the feature dimension of the input\n",
    "            self.W = nn.Parameter(torch.empty(input_dim, self.dim))\n",
    "            nn.init.xavier_uniform_(self.W)  # Xavier initialization for W\n",
    "        \n",
    "        # Apply soft attention mechanism\n",
    "        attention_scores = torch.tanh(inputs @ self.W + self.b) @ self.q\n",
    "        print(f\"AttLayer2_torch: attention_scores shape: {attention_scores.shape}\")\n",
    "        attention_weights = F.softmax(attention_scores.squeeze(-1), dim=-1).unsqueeze(-1)\n",
    "        print(f\"AttLayer2_torch: attention_weights shape: {attention_weights.shape}\")\n",
    "        weighted_inputs = inputs * attention_weights\n",
    "        output = torch.sum(weighted_inputs, dim=1)\n",
    "        print(f\"AttLayer2_torch: output shape: {output.shape}\")\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "class NRMSModelPytorch_2(nn.Module):\n",
    "    def __init__(self, hparams, word2vec_embedding=None, word_emb_dim=300, vocab_size=32000, seed=None):\n",
    "        super(NRMSModelPytorch_2, self).__init__()\n",
    "        self.hparams = hparams\n",
    "        self.seed = seed\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        # Initialize word embeddings\n",
    "        if word2vec_embedding is None:\n",
    "            self.word2vec_embedding = torch.randn(vocab_size, word_emb_dim)\n",
    "        else:\n",
    "            self.word2vec_embedding = torch.from_numpy(word2vec_embedding).float()\n",
    "        self.embedding_layer = nn.Embedding.from_pretrained(self.word2vec_embedding, freeze=False)\n",
    "\n",
    "        # Build model components\n",
    "        self.news_encoder = self._build_newsencoder()\n",
    "        self.user_encoder = self._build_userencoder(self.news_encoder)\n",
    "\n",
    "        # Define optimizer and loss\n",
    "        self.criterion = self._get_loss(hparams.loss)\n",
    "        self.optimizer = self._get_opt(hparams.optimizer, hparams.learning_rate)\n",
    "\n",
    "    def _get_loss(self, loss):\n",
    "        if loss == \"cross_entropy_loss\":\n",
    "            return nn.CrossEntropyLoss()\n",
    "        elif loss == \"log_loss\":\n",
    "            return nn.BCELoss()\n",
    "        else:\n",
    "            raise ValueError(f\"this loss not defined {loss}\")\n",
    "\n",
    "    def _get_opt(self, optimizer, lr):\n",
    "        if optimizer == \"adam\":\n",
    "            return optim.Adam(self.parameters(), lr=lr)\n",
    "        else:\n",
    "            raise ValueError(f\"this optimizer not defined {optimizer}\")\n",
    "\n",
    "    def _build_userencoder(self, titleencoder):\n",
    "        # Define user encoder using SelfAttention and AttLayer2 modules\n",
    "        class UserEncoder(nn.Module):\n",
    "            def __init__(self, hparams, titleencoder):\n",
    "                super(UserEncoder, self).__init__()\n",
    "                self.titleencoder = titleencoder\n",
    "                self.attention = MultiHeadedAttention(hparams.head_num, hparams.head_num)\n",
    "                self.att_layer = AttLayer2_torch(hparams.attention_hidden_dim)\n",
    "\n",
    "            def forward(self, his_input_title):\n",
    "                # Encode each news in the history\n",
    "                click_title_presents = torch.stack([self.titleencoder(title) for title in his_input_title], dim=1)\n",
    "                y = self.attention(click_title_presents,click_title_presents,click_title_presents)\n",
    "                user_present = self.att_layer(y)\n",
    "                return user_present\n",
    "\n",
    "        return UserEncoder(self.hparams, titleencoder)\n",
    "\n",
    "    def _build_newsencoder(self):\n",
    "        # Define news encoder using embedding and attention layers\n",
    "        class NewsEncoder(nn.Module):\n",
    "            def __init__(self, embedding_layer, hparams, seed):\n",
    "                super(NewsEncoder, self).__init__()\n",
    "                self.embedding = embedding_layer\n",
    "                self.dropout1 = nn.Dropout(hparams.dropout)  # Use attribute access here\n",
    "                self.attention = MultiHeadedAttention(hparams.head_num, hparams.head_dim)\n",
    "                self.dropout2 = nn.Dropout(hparams.dropout)  # Use attribute access here\n",
    "                self.att_layer = AttLayer2_torch(hparams.attention_hidden_dim, seed=seed)\n",
    "\n",
    "\n",
    "            def forward(self, sequences_input_title):\n",
    "                # Convert input to LongTensor\n",
    "                sequences_input_title = sequences_input_title.long()\n",
    "                embedded_sequences_title = self.embedding(sequences_input_title)\n",
    "                y = self.dropout1(embedded_sequences_title)\n",
    "\n",
    "                y = self.attention(y,y,y)\n",
    "                y = self.dropout2(y)\n",
    "                pred_title = self.att_layer(y)\n",
    "                return pred_title\n",
    "\n",
    "        return NewsEncoder(self.embedding_layer, self.hparams, self.seed)\n",
    "\n",
    "    def forward(self, his_input_title, pred_input_title):\n",
    "        print(f\"NRMSModelPytorch_2: his_input_title shape: {his_input_title.shape}, pred_input_title shape: {pred_input_title.shape}\")\n",
    "        \n",
    "        user_vector = self.user_encoder(his_input_title)\n",
    "        print(f\"NRMSModelPytorch_2: user_vector shape: {user_vector.shape}\")\n",
    "        \n",
    "        news_vectors = torch.stack([self.news_encoder(news) for news in pred_input_title], dim=1)\n",
    "        print(f\"NRMSModelPytorch_2: news_vectors shape: {news_vectors.shape}\")\n",
    "        \n",
    "        scores = torch.bmm(news_vectors, user_vector.unsqueeze(-1)).squeeze(-1)\n",
    "        print(f\"NRMSModelPytorch_2: scores shape: {scores.shape}\")\n",
    "        return torch.softmax(scores, dim=-1)\n",
    "\n",
    "    def predict(self, his_input_title, pred_input_title_one):\n",
    "        print(f\"NRMSModelPytorch_2 (predict): his_input_title shape: {his_input_title.shape}, pred_input_title_one shape: {pred_input_title_one.shape}\")\n",
    "        \n",
    "        user_vector = self.user_encoder(his_input_title)\n",
    "        print(f\"NRMSModelPytorch_2 (predict): user_vector shape: {user_vector.shape}\")\n",
    "        \n",
    "        news_vector = self.news_encoder(pred_input_title_one)\n",
    "        print(f\"NRMSModelPytorch_2 (predict): news_vector shape: {news_vector.shape}\")\n",
    "        \n",
    "        prediction = torch.sigmoid(torch.dot(news_vector, user_vector))\n",
    "        print(f\"NRMSModelPytorch_2 (predict): prediction shape: {prediction.shape}\")\n",
    "        return prediction\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AttLayer2_torch(nn.Module):\n",
    "    \"\"\"Soft alignment attention implementation in PyTorch.\"\"\"\n",
    "    \n",
    "    def __init__(self, dim=200, seed=0):\n",
    "        super(AttLayer2_torch, self).__init__()\n",
    "        self.dim = dim\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "        # Initialize W, b, and q but do not specify input dimension yet\n",
    "        self.W = None\n",
    "        self.b = nn.Parameter(torch.zeros(dim))\n",
    "        self.q = nn.Parameter(torch.empty(dim, 1))\n",
    "        \n",
    "        # Initialize q using Xavier initialization\n",
    "        nn.init.xavier_uniform_(self.q)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Dynamically initialize W based on the input's feature size\n",
    "        if self.W is None:\n",
    "            input_dim = inputs.size(-1)  # Get the feature dimension of the input\n",
    "            self.W = nn.Parameter(torch.empty(input_dim, self.dim))\n",
    "            nn.init.xavier_uniform_(self.W)  # Xavier initialization for W\n",
    "        \n",
    "        # Apply soft attention mechanism\n",
    "        #print(\"input\", inputs.shape)\n",
    "        attention = torch.tanh(inputs @ self.W + self.b)\n",
    "        attention = attention @ self.q\n",
    "        #print(\"attention\", attention.shape)\n",
    "        attention = torch.squeeze(attention, dim=-1)\n",
    "        #print(\"attention2\", attention.shape)\n",
    "        \n",
    "        attention_weights = F.softmax(attention, dim=-1)\n",
    "        attention_weights = attention_weights.unsqueeze(-1)\n",
    "        #print(\"attention_weights\", attention_weights.shape)\n",
    "\n",
    "        weighted_input = inputs * attention_weights\n",
    "        return torch.sum(weighted_input, dim=1)\n",
    "\n",
    "\n",
    "class SelfAttention_torch(nn.Module):\n",
    "    \"\"\"Multi-head self-attention implementation in PyTorch.\"\"\"\n",
    "    \n",
    "    def __init__(self, multiheads, head_dim, seed=0, mask_right=False):\n",
    "        super(SelfAttention_torch, self).__init__()\n",
    "        self.multiheads = multiheads\n",
    "        self.head_dim = head_dim\n",
    "        self.output_dim = multiheads * head_dim\n",
    "        self.mask_right = mask_right\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "        # Initially set input_dim as None\n",
    "        self.input_dim = None\n",
    "\n",
    "        # Placeholder for the Linear layers for Q, K, V\n",
    "        self.WQ = None\n",
    "        self.WK = None\n",
    "        self.WV = None\n",
    "\n",
    "    def _mask(self, inputs, seq_len, mode=\"add\"):\n",
    "        \"\"\"Apply masking operation to inputs based on sequence length.\"\"\"\n",
    "        if seq_len is None:\n",
    "            return inputs\n",
    "        mask = (torch.arange(inputs.size(1)) < seq_len.unsqueeze(1)).float()\n",
    "        if mode == \"mul\":\n",
    "            return inputs * mask\n",
    "        elif mode == \"add\":\n",
    "            return inputs - (1 - mask) * 1e12\n",
    "\n",
    "    def forward(self, Q_seq, K_seq, V_seq, Q_len=None, V_len=None):\n",
    "        # Print input shapes before passing them to attention\n",
    "        \n",
    "        # Set input_dim dynamically based on the input shape\n",
    "        if self.input_dim is None:\n",
    "            self.input_dim = Q_seq.size(-1)  # Set input_dim from the last dimension of Q_seq\n",
    "\n",
    "            # Initialize the Linear layers with the correct input dimension\n",
    "            self.WQ = nn.Linear(self.input_dim, self.output_dim)\n",
    "            self.WK = nn.Linear(self.input_dim, self.output_dim)\n",
    "            self.WV = nn.Linear(self.input_dim, self.output_dim)\n",
    "\n",
    "            # Get input and output shapes\n",
    "            input_features = self.WQ.in_features\n",
    "            output_features = self.WQ.out_features\n",
    "\n",
    "            print(f\"Input features: {input_features}, Output features: {output_features}\")\n",
    "\n",
    "        # Linear transformations for Q, K, and V\n",
    "        Q = self.WQ(Q_seq).view(-1, Q_seq.size(1), self.multiheads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        K = self.WK(K_seq).view(-1, K_seq.size(1), self.multiheads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        V = self.WV(V_seq).view(-1, V_seq.size(1), self.multiheads, self.head_dim).permute(0, 2, 1, 3)\n",
    "\n",
    "        # Scaled dot-product attention\n",
    "        A = (Q @ K.transpose(-2, -1)) / torch.sqrt(torch.tensor(self.head_dim, dtype=torch.float32))\n",
    "        if self.mask_right:\n",
    "            ones = torch.ones_like(A[0, 0])\n",
    "            mask = torch.tril(ones) * 1e12\n",
    "            A = A - mask\n",
    "\n",
    "        # Apply softmax to attention scores\n",
    "        A = F.softmax(A, dim=-1)\n",
    "\n",
    "        # Weighted sum of values\n",
    "        O = (A @ V).permute(0, 2, 1, 3).contiguous().view(-1, Q_seq.size(1), self.output_dim)\n",
    "        #print(\"atention shape: \", O.shape)\n",
    "        # Apply the mask (if applicable)\n",
    "        return self._mask(O, Q_len, \"mul\") if Q_len is not None else O\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NRMS model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "class NRMSModelPytorch(nn.Module):\n",
    "    def __init__(self, hparams, word2vec_embedding=None, word_emb_dim=300, vocab_size=32000, seed=None):\n",
    "        super(NRMSModelPytorch, self).__init__()\n",
    "        self.hparams = hparams\n",
    "        self.seed = seed\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        # Initialize word embeddings\n",
    "        if word2vec_embedding is None:\n",
    "            self.word2vec_embedding = torch.randn(vocab_size, word_emb_dim)\n",
    "        else:\n",
    "            self.word2vec_embedding = torch.from_numpy(word2vec_embedding).float()\n",
    "        self.embedding_layer = nn.Embedding.from_pretrained(self.word2vec_embedding, freeze=False)\n",
    "\n",
    "        # Build model components\n",
    "        self.news_encoder = self._build_newsencoder()\n",
    "        self.user_encoder = self._build_userencoder(self.news_encoder)\n",
    "\n",
    "        # Define optimizer and loss\n",
    "        self.criterion = self._get_loss(hparams.loss)\n",
    "        self.optimizer = self._get_opt(hparams.optimizer, hparams.learning_rate)\n",
    "\n",
    "    def _get_loss(self, loss):\n",
    "        if loss == \"cross_entropy_loss\":\n",
    "            return nn.CrossEntropyLoss()\n",
    "        elif loss == \"log_loss\":\n",
    "            print(\"BCE is used\")\n",
    "            return nn.BCELoss()\n",
    "        else:\n",
    "            raise ValueError(f\"this loss not defined {loss}\")\n",
    "\n",
    "    def _get_opt(self, optimizer, lr):\n",
    "        if optimizer == \"adam\":\n",
    "            return optim.Adam(self.parameters(), lr=lr)\n",
    "        else:\n",
    "            raise ValueError(f\"this optimizer not defined {optimizer}\")\n",
    "\n",
    "    def _build_userencoder(self, titleencoder):\n",
    "        # Define user encoder using SelfAttention and AttLayer2 modules\n",
    "        class UserEncoder(nn.Module):\n",
    "            def __init__(self, hparams, titleencoder):\n",
    "                super(UserEncoder, self).__init__()\n",
    "                self.titleencoder = titleencoder\n",
    "                self.attention = SelfAttention_torch(hparams.head_num, hparams.head_num)\n",
    "                self.att_layer = AttLayer2_torch(hparams.attention_hidden_dim)\n",
    "\n",
    "            def forward(self, his_input_title):\n",
    "                #print(\"input:\", his_input_title.shape)\n",
    "                # Encode each news in the history\n",
    "                click_title_presents = torch.stack([self.titleencoder(title) for title in his_input_title], dim=0)\n",
    "                #print(\"Vlick\",click_title_presents.shape)\n",
    "                y = self.attention(click_title_presents,click_title_presents,click_title_presents)\n",
    "                #print(\"y.shape\",y.shape)\n",
    "                user_present = self.att_layer(y)\n",
    "                return user_present\n",
    "\n",
    "        return UserEncoder(self.hparams, titleencoder)\n",
    "\n",
    "    def _build_newsencoder(self):\n",
    "        # Define news encoder using embedding and attention layers\n",
    "        class NewsEncoder(nn.Module):\n",
    "            def __init__(self, embedding_layer, hparams, seed):\n",
    "                super(NewsEncoder, self).__init__()\n",
    "                self.embedding = embedding_layer\n",
    "                self.dropout1 = nn.Dropout(hparams.dropout)  # Use attribute access here\n",
    "                self.attention = SelfAttention_torch(hparams.head_num, hparams.head_dim, seed=seed)\n",
    "                self.dropout2 = nn.Dropout(hparams.dropout)  # Use attribute access here\n",
    "                self.att_layer = AttLayer2_torch(hparams.attention_hidden_dim, seed=seed)\n",
    "\n",
    "\n",
    "            def forward(self, sequences_input_title):\n",
    "                # Convert input to LongTensor\n",
    "                #print(\"sequence\",sequences_input_title.shape)\n",
    "                sequences_input_title = sequences_input_title.long()\n",
    "                embedded_sequences_title = self.embedding(sequences_input_title)\n",
    "                #print(\"embedded\",embedded_sequences_title.shape)\n",
    "                y = self.dropout1(embedded_sequences_title)\n",
    "\n",
    "                y = self.attention(y,y,y)\n",
    "                y = self.dropout2(y)\n",
    "                pred_title = self.att_layer(y)\n",
    "                #print(\"pred\",pred_title.shape)\n",
    "                return pred_title\n",
    "\n",
    "        return NewsEncoder(self.embedding_layer, self.hparams, self.seed)\n",
    "\n",
    "    def forward(self, his_input_title, pred_input_title):\n",
    "        #print(his_input_title.shape)\n",
    "       # print(pred_input_title.shape)\n",
    "        user_present = self.user_encoder(his_input_title)\n",
    "        #print(\"user: \", user_present.shape)\n",
    "        news_present = torch.stack([self.news_encoder(news) for news in pred_input_title], dim=0)\n",
    "        #print(\"news: \", news_present.shape)\n",
    "        #print(\"new user: \", user_present.unsqueeze(-1).shape)\n",
    "        preds = torch.bmm(news_present, user_present.unsqueeze(-1)).squeeze(-1)\n",
    "        #print(\"npreds: \", preds.shape)\n",
    "        return torch.sigmoid(preds)\n",
    "\n",
    "    def predict(self, his_input_title, pred_input_title_one):\n",
    "        \n",
    "        user_present = self.user_encoder(his_input_title)\n",
    "        news_present_one = self.news_encoder(pred_input_title_one)\n",
    "        pred_one = torch.sigmoid(torch.dot(news_present_one, user_present))\n",
    "        return pred_one\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NRMS Model Implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCE is used\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow as tf\n",
    "\n",
    "class hparams_nrms:\n",
    "    # INPUT DIMENTIONS:\n",
    "    title_size: int = 30\n",
    "    history_size: int = 50\n",
    "    # MODEL ARCHITECTURE\n",
    "    head_num: int = 20\n",
    "    head_dim: int = 20\n",
    "    attention_hidden_dim: int = 200\n",
    "    # MODEL OPTIMIZER:\n",
    "    optimizer: str = \"adam\"\n",
    "    loss: str = \"log_loss\"\n",
    "    dropout: float = 0.2\n",
    "    learning_rate: float = 0.0001\n",
    "\n",
    "MODEL_NAME = \"NRMS\"\n",
    "LOG_DIR = f\"downloads/runs/{MODEL_NAME}\"\n",
    "MODEL_WEIGHTS = \"downloads/data/state_dict/NRMS/weights.weights.h5\"\n",
    "\n",
    "# CALLBACKS\n",
    "#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=LOG_DIR, histogram_freq=1)\n",
    "#early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2)\n",
    "#modelcheckpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    #filepath=MODEL_WEIGHTS, save_best_only=False, save_weights_only=True, verbose=1\n",
    "#)\n",
    "\n",
    "hparams_nrms.history_size = HISTORY_SIZE\n",
    "model = NRMSModelPytorch(\n",
    "    hparams=hparams_nrms,\n",
    "    word2vec_embedding=word2vec_embedding,\n",
    "    seed=42,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  tensor([0.5062, 0.5069, 0.5044, 0.5129, 0.4996], grad_fn=<SliceBackward0>)\n",
      "Labels     :  tensor([0., 0., 0., 0., 1.])\n",
      "Predictions:  tensor([0.4999, 0.5155, 0.4947, 0.5068, 0.5040], grad_fn=<SliceBackward0>)\n",
      "Labels     :  tensor([0., 0., 1., 0., 0.])\n",
      "Predictions:  tensor([0.5127, 0.5126, 0.5075, 0.5144, 0.5048], grad_fn=<SliceBackward0>)\n",
      "Labels     :  tensor([0., 0., 0., 0., 1.])\n",
      "Predictions:  tensor([0.5047, 0.5024, 0.4949, 0.5090, 0.5037], grad_fn=<SliceBackward0>)\n",
      "Labels     :  tensor([0., 0., 0., 0., 1.])\n",
      "Epoch 1/10, Loss: 0.7011\n",
      "Predictions:  tensor([0.5041, 0.5038, 0.5041, 0.5085, 0.5074])\n",
      "Labels     :  tensor([1., 0., 0., 0., 0.])\n",
      "Predictions:  tensor([0.5041, 0.5010, 0.4992, 0.5084, 0.5047])\n",
      "Labels     :  tensor([0., 0., 0., 0., 0.])\n",
      "Predictions:  tensor([0.5088, 0.5081, 0.5156, 0.5068, 0.4976])\n",
      "Labels     :  tensor([0., 0., 0., 0., 0.])\n",
      "Predictions:  tensor([0.5087, 0.5042, 0.5035, 0.5116, 0.5142])\n",
      "Labels     :  tensor([0., 0., 0., 0., 0.])\n",
      "Validation Loss: 0.7048\n",
      "Predictions:  tensor([0.5021, 0.5126, 0.5125, 0.5026, 0.5132], grad_fn=<SliceBackward0>)\n",
      "Labels     :  tensor([0., 0., 0., 0., 1.])\n",
      "Predictions:  tensor([0.5012, 0.5162, 0.4920, 0.5024, 0.5041], grad_fn=<SliceBackward0>)\n",
      "Labels     :  tensor([0., 0., 1., 0., 0.])\n",
      "Predictions:  tensor([0.5059, 0.5008, 0.5180, 0.5054, 0.5111], grad_fn=<SliceBackward0>)\n",
      "Labels     :  tensor([0., 0., 0., 0., 1.])\n",
      "Predictions:  tensor([0.4964, 0.4976, 0.4981, 0.5094, 0.5078], grad_fn=<SliceBackward0>)\n",
      "Labels     :  tensor([0., 0., 0., 0., 1.])\n",
      "Epoch 2/10, Loss: 0.6994\n",
      "Predictions:  tensor([0.5028, 0.5028, 0.5030, 0.5072, 0.5062])\n",
      "Labels     :  tensor([1., 0., 0., 0., 0.])\n",
      "Predictions:  tensor([0.5029, 0.4998, 0.4980, 0.5072, 0.5034])\n",
      "Labels     :  tensor([0., 0., 0., 0., 0.])\n",
      "Predictions:  tensor([0.5076, 0.5069, 0.5143, 0.5055, 0.4962])\n",
      "Labels     :  tensor([0., 0., 0., 0., 0.])\n",
      "Predictions:  tensor([0.5075, 0.5028, 0.5021, 0.5104, 0.5130])\n",
      "Labels     :  tensor([0., 0., 0., 0., 0.])\n",
      "Validation Loss: 0.7028\n",
      "Predictions:  tensor([0.4985, 0.5073, 0.5010, 0.5111, 0.5048], grad_fn=<SliceBackward0>)\n",
      "Labels     :  tensor([0., 0., 0., 0., 1.])\n",
      "Predictions:  tensor([0.4956, 0.5104, 0.4935, 0.5074, 0.4940], grad_fn=<SliceBackward0>)\n",
      "Labels     :  tensor([0., 0., 1., 0., 0.])\n",
      "Predictions:  tensor([0.5021, 0.5052, 0.5036, 0.5042, 0.5135], grad_fn=<SliceBackward0>)\n",
      "Labels     :  tensor([0., 0., 0., 0., 1.])\n",
      "Predictions:  tensor([0.4998, 0.5015, 0.4911, 0.5041, 0.5020], grad_fn=<SliceBackward0>)\n",
      "Labels     :  tensor([0., 0., 0., 0., 1.])\n",
      "Epoch 3/10, Loss: 0.6974\n",
      "Predictions:  tensor([0.5016, 0.5017, 0.5020, 0.5060, 0.5050])\n",
      "Labels     :  tensor([1., 0., 0., 0., 0.])\n",
      "Predictions:  tensor([0.5016, 0.4986, 0.4968, 0.5061, 0.5022])\n",
      "Labels     :  tensor([0., 0., 0., 0., 0.])\n",
      "Predictions:  tensor([0.5065, 0.5057, 0.5130, 0.5043, 0.4949])\n",
      "Labels     :  tensor([0., 0., 0., 0., 0.])\n",
      "Predictions:  tensor([0.5063, 0.5014, 0.5007, 0.5093, 0.5118])\n",
      "Labels     :  tensor([0., 0., 0., 0., 0.])\n",
      "Validation Loss: 0.7008\n",
      "Predictions:  tensor([0.4969, 0.4968, 0.5026, 0.5063, 0.5063], grad_fn=<SliceBackward0>)\n",
      "Labels     :  tensor([0., 0., 0., 0., 1.])\n",
      "Predictions:  tensor([0.4960, 0.5160, 0.4945, 0.4978, 0.4968], grad_fn=<SliceBackward0>)\n",
      "Labels     :  tensor([0., 0., 1., 0., 0.])\n",
      "Predictions:  tensor([0.5052, 0.4985, 0.5029, 0.5059, 0.5086], grad_fn=<SliceBackward0>)\n",
      "Labels     :  tensor([0., 0., 0., 0., 1.])\n",
      "Predictions:  tensor([0.4922, 0.5092, 0.4946, 0.5053, 0.5045], grad_fn=<SliceBackward0>)\n",
      "Labels     :  tensor([0., 0., 0., 0., 1.])\n",
      "Epoch 4/10, Loss: 0.6952\n",
      "Predictions:  tensor([0.5003, 0.5006, 0.5009, 0.5047, 0.5038])\n",
      "Labels     :  tensor([1., 0., 0., 0., 0.])\n",
      "Predictions:  tensor([0.5003, 0.4975, 0.4957, 0.5049, 0.5010])\n",
      "Labels     :  tensor([0., 0., 0., 0., 0.])\n",
      "Predictions:  tensor([0.5054, 0.5045, 0.5117, 0.5030, 0.4936])\n",
      "Labels     :  tensor([0., 0., 0., 0., 0.])\n",
      "Predictions:  tensor([0.5051, 0.5001, 0.4992, 0.5081, 0.5106])\n",
      "Labels     :  tensor([0., 0., 0., 0., 0.])\n",
      "Validation Loss: 0.6988\n",
      "Predictions:  tensor([0.4915, 0.5032, 0.4977, 0.5016, 0.4976], grad_fn=<SliceBackward0>)\n",
      "Labels     :  tensor([0., 0., 0., 0., 1.])\n",
      "Predictions:  tensor([0.4905, 0.5094, 0.4950, 0.4981, 0.4909], grad_fn=<SliceBackward0>)\n",
      "Labels     :  tensor([0., 0., 1., 0., 0.])\n",
      "Predictions:  tensor([0.4992, 0.5025, 0.5087, 0.5029, 0.5062], grad_fn=<SliceBackward0>)\n",
      "Labels     :  tensor([0., 0., 0., 0., 1.])\n",
      "Predictions:  tensor([0.4955, 0.4959, 0.4885, 0.4996, 0.4992], grad_fn=<SliceBackward0>)\n",
      "Labels     :  tensor([0., 0., 0., 0., 1.])\n",
      "Epoch 5/10, Loss: 0.6935\n",
      "Predictions:  tensor([0.4990, 0.4996, 0.4999, 0.5034, 0.5027])\n",
      "Labels     :  tensor([1., 0., 0., 0., 0.])\n",
      "Predictions:  tensor([0.4991, 0.4963, 0.4945, 0.5037, 0.4998])\n",
      "Labels     :  tensor([0., 0., 0., 0., 0.])\n",
      "Predictions:  tensor([0.5043, 0.5034, 0.5104, 0.5017, 0.4922])\n",
      "Labels     :  tensor([0., 0., 0., 0., 0.])\n",
      "Predictions:  tensor([0.5039, 0.4987, 0.4978, 0.5070, 0.5094])\n",
      "Labels     :  tensor([0., 0., 0., 0., 0.])\n",
      "Validation Loss: 0.6968\n",
      "Predictions:  tensor([0.5015, 0.5030, 0.4997, 0.5046, 0.5073], grad_fn=<SliceBackward0>)\n",
      "Labels     :  tensor([0., 0., 0., 0., 1.])\n",
      "Predictions:  tensor([0.4954, 0.5026, 0.4882, 0.4936, 0.4968], grad_fn=<SliceBackward0>)\n",
      "Labels     :  tensor([0., 0., 1., 0., 0.])\n",
      "Predictions:  tensor([0.5037, 0.4968, 0.4984, 0.5025, 0.5084], grad_fn=<SliceBackward0>)\n",
      "Labels     :  tensor([0., 0., 0., 0., 1.])\n",
      "Predictions:  tensor([0.4931, 0.4970, 0.4926, 0.5043, 0.4953], grad_fn=<SliceBackward0>)\n",
      "Labels     :  tensor([0., 0., 0., 0., 1.])\n",
      "Epoch 6/10, Loss: 0.6912\n",
      "Predictions:  tensor([0.4977, 0.4985, 0.4988, 0.5022, 0.5015])\n",
      "Labels     :  tensor([1., 0., 0., 0., 0.])\n",
      "Predictions:  tensor([0.4978, 0.4951, 0.4933, 0.5026, 0.4986])\n",
      "Labels     :  tensor([0., 0., 0., 0., 0.])\n",
      "Predictions:  tensor([0.5032, 0.5022, 0.5091, 0.5004, 0.4909])\n",
      "Labels     :  tensor([0., 0., 0., 0., 0.])\n",
      "Predictions:  tensor([0.5027, 0.4973, 0.4964, 0.5059, 0.5082])\n",
      "Labels     :  tensor([0., 0., 0., 0., 0.])\n",
      "Validation Loss: 0.6948\n",
      "Predictions:  tensor([0.4916, 0.4991, 0.5001, 0.5014, 0.5021], grad_fn=<SliceBackward0>)\n",
      "Labels     :  tensor([0., 0., 0., 0., 1.])\n",
      "Predictions:  tensor([0.4931, 0.5037, 0.4907, 0.4980, 0.4955], grad_fn=<SliceBackward0>)\n",
      "Labels     :  tensor([0., 0., 1., 0., 0.])\n",
      "Predictions:  tensor([0.4927, 0.5004, 0.5023, 0.5003, 0.5036], grad_fn=<SliceBackward0>)\n",
      "Labels     :  tensor([0., 0., 0., 0., 1.])\n",
      "Predictions:  tensor([0.4992, 0.4962, 0.4880, 0.5101, 0.4949], grad_fn=<SliceBackward0>)\n",
      "Labels     :  tensor([0., 0., 0., 0., 1.])\n",
      "Epoch 7/10, Loss: 0.6894\n",
      "Predictions:  tensor([0.4965, 0.4974, 0.4978, 0.5009, 0.5003])\n",
      "Labels     :  tensor([1., 0., 0., 0., 0.])\n",
      "Predictions:  tensor([0.4966, 0.4940, 0.4921, 0.5014, 0.4974])\n",
      "Labels     :  tensor([0., 0., 0., 0., 0.])\n",
      "Predictions:  tensor([0.5021, 0.5010, 0.5078, 0.4991, 0.4896])\n",
      "Labels     :  tensor([0., 0., 0., 0., 0.])\n",
      "Predictions:  tensor([0.5015, 0.4959, 0.4950, 0.5047, 0.5070])\n",
      "Labels     :  tensor([0., 0., 0., 0., 0.])\n",
      "Validation Loss: 0.6929\n",
      "Predictions:  tensor([0.4969, 0.4951, 0.4953, 0.4933, 0.4962], grad_fn=<SliceBackward0>)\n",
      "Labels     :  tensor([0., 0., 0., 0., 1.])\n",
      "Predictions:  tensor([0.4883, 0.5014, 0.4944, 0.4938, 0.4866], grad_fn=<SliceBackward0>)\n",
      "Labels     :  tensor([0., 0., 1., 0., 0.])\n",
      "Predictions:  tensor([0.4961, 0.5084, 0.4956, 0.5007, 0.5003], grad_fn=<SliceBackward0>)\n",
      "Labels     :  tensor([0., 0., 0., 0., 1.])\n",
      "Predictions:  tensor([0.4938, 0.4856, 0.4842, 0.4970, 0.4930], grad_fn=<SliceBackward0>)\n",
      "Labels     :  tensor([0., 0., 0., 0., 1.])\n",
      "Epoch 8/10, Loss: 0.6866\n",
      "Predictions:  tensor([0.4952, 0.4964, 0.4968, 0.4997, 0.4991])\n",
      "Labels     :  tensor([1., 0., 0., 0., 0.])\n",
      "Predictions:  tensor([0.4953, 0.4928, 0.4909, 0.5003, 0.4962])\n",
      "Labels     :  tensor([0., 0., 0., 0., 0.])\n",
      "Predictions:  tensor([0.5010, 0.4998, 0.5065, 0.4979, 0.4883])\n",
      "Labels     :  tensor([0., 0., 0., 0., 0.])\n",
      "Predictions:  tensor([0.5004, 0.4946, 0.4936, 0.5036, 0.5059])\n",
      "Labels     :  tensor([0., 0., 0., 0., 0.])\n",
      "Validation Loss: 0.6909\n",
      "Predictions:  tensor([0.4933, 0.4977, 0.4960, 0.4961, 0.4993], grad_fn=<SliceBackward0>)\n",
      "Labels     :  tensor([0., 0., 0., 0., 1.])\n",
      "Predictions:  tensor([0.4800, 0.4994, 0.4911, 0.4920, 0.4908], grad_fn=<SliceBackward0>)\n",
      "Labels     :  tensor([0., 0., 1., 0., 0.])\n",
      "Predictions:  tensor([0.4898, 0.4900, 0.4896, 0.4983, 0.5014], grad_fn=<SliceBackward0>)\n",
      "Labels     :  tensor([0., 0., 0., 0., 1.])\n",
      "Predictions:  tensor([0.4835, 0.4934, 0.4873, 0.4960, 0.4924], grad_fn=<SliceBackward0>)\n",
      "Labels     :  tensor([0., 0., 0., 0., 1.])\n",
      "Epoch 9/10, Loss: 0.6849\n",
      "Predictions:  tensor([0.4940, 0.4953, 0.4957, 0.4984, 0.4979])\n",
      "Labels     :  tensor([1., 0., 0., 0., 0.])\n",
      "Predictions:  tensor([0.4941, 0.4916, 0.4898, 0.4991, 0.4950])\n",
      "Labels     :  tensor([0., 0., 0., 0., 0.])\n",
      "Predictions:  tensor([0.4999, 0.4987, 0.5052, 0.4966, 0.4869])\n",
      "Labels     :  tensor([0., 0., 0., 0., 0.])\n",
      "Predictions:  tensor([0.4992, 0.4932, 0.4921, 0.5025, 0.5047])\n",
      "Labels     :  tensor([0., 0., 0., 0., 0.])\n",
      "Validation Loss: 0.6890\n",
      "Predictions:  tensor([0.4862, 0.4910, 0.4920, 0.4970, 0.4996], grad_fn=<SliceBackward0>)\n",
      "Labels     :  tensor([0., 0., 0., 0., 1.])\n",
      "Predictions:  tensor([0.4862, 0.4910, 0.4920, 0.4970, 0.4996], grad_fn=<SliceBackward0>)\n",
      "Labels     :  tensor([0., 0., 0., 0., 1.])\n",
      "Loss:  0.6826130151748657\n",
      "Predictions:  tensor([0.4816, 0.4936, 0.4893, 0.4940, 0.4803], grad_fn=<SliceBackward0>)\n",
      "Labels     :  tensor([0., 0., 1., 0., 0.])\n",
      "Predictions:  tensor([0.4816, 0.4936, 0.4893, 0.4940, 0.4803], grad_fn=<SliceBackward0>)\n",
      "Labels     :  tensor([0., 0., 1., 0., 0.])\n",
      "Loss:  0.6838162541389465\n",
      "Predictions:  tensor([0.4951, 0.4915, 0.4951, 0.4896, 0.4967], grad_fn=<SliceBackward0>)\n",
      "Labels     :  tensor([0., 0., 0., 0., 1.])\n",
      "Predictions:  tensor([0.4951, 0.4915, 0.4951, 0.4896, 0.4967], grad_fn=<SliceBackward0>)\n",
      "Labels     :  tensor([0., 0., 0., 0., 1.])\n",
      "Loss:  0.6835719347000122\n",
      "Predictions:  tensor([0.4822, 0.4834, 0.4864, 0.4984, 0.4902], grad_fn=<SliceBackward0>)\n",
      "Labels     :  tensor([0., 0., 0., 0., 1.])\n",
      "Predictions:  tensor([0.4822, 0.4834, 0.4864, 0.4984, 0.4902], grad_fn=<SliceBackward0>)\n",
      "Labels     :  tensor([0., 0., 0., 0., 1.])\n",
      "Loss:  0.6830003261566162\n",
      "Epoch 10/10, Loss: 0.6833\n",
      "Predictions:  tensor([0.4927, 0.4943, 0.4947, 0.4972, 0.4967])\n",
      "Labels     :  tensor([1., 0., 0., 0., 0.])\n",
      "Predictions:  tensor([0.4927, 0.4943, 0.4947, 0.4972, 0.4967])\n",
      "Labels     :  tensor([1., 0., 0., 0., 0.])\n",
      "Loss:  0.6868646144866943\n",
      "Predictions:  tensor([0.4928, 0.4905, 0.4886, 0.4980, 0.4938])\n",
      "Labels     :  tensor([0., 0., 0., 0., 0.])\n",
      "Predictions:  tensor([0.4928, 0.4905, 0.4886, 0.4980, 0.4938])\n",
      "Labels     :  tensor([0., 0., 0., 0., 0.])\n",
      "Loss:  0.6872554421424866\n",
      "Predictions:  tensor([0.4988, 0.4975, 0.5039, 0.4953, 0.4856])\n",
      "Labels     :  tensor([0., 0., 0., 0., 0.])\n",
      "Predictions:  tensor([0.4988, 0.4975, 0.5039, 0.4953, 0.4856])\n",
      "Labels     :  tensor([0., 0., 0., 0., 0.])\n",
      "Loss:  0.6871173977851868\n",
      "Predictions:  tensor([0.4980, 0.4919, 0.4907, 0.5013, 0.5035])\n",
      "Labels     :  tensor([0., 0., 0., 0., 0.])\n",
      "Predictions:  tensor([0.4980, 0.4919, 0.4907, 0.5013, 0.5035])\n",
      "Labels     :  tensor([0., 0., 0., 0., 0.])\n",
      "Loss:  0.6868791580200195\n",
      "Validation Loss: 0.6870\n"
     ]
    }
   ],
   "source": [
    "# Move the model to the appropriate device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define your dataloaders (ensure they are instances of PyTorch DataLoader)\n",
    "train_dataloader = train_pytorch_dataset  # Created using NRMSDataLoader\n",
    "val_dataloader =val_pytorch_dataset      # Created using NRMSDataLoader\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    total_loss = 0\n",
    "    k = 0\n",
    "    for (his_input_title, pred_input_title), labels in train_dataloader:\n",
    "        # Convert numpy arrays to PyTorch tensors and move to the appropriate device\n",
    "        his_input_title = torch.tensor(his_input_title).to(device)\n",
    "        pred_input_title = torch.tensor(pred_input_title).to(device)\n",
    "        labels = torch.tensor(labels).to(device)\n",
    "        #print(\"______________________________________________________\")\n",
    "        #print(\"User history input: \", his_input_title.shape)\n",
    "        #print(\"News Items: \", pred_input_title.shape)\n",
    "        #print(\"Target: \", labels.shape)\n",
    "        \n",
    "        # Zero the gradients\n",
    "        model.optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        predictions = model(his_input_title, pred_input_title)\n",
    "        #print(\"Predictions: \", predictions.shape)\n",
    "\n",
    "        # Reshape labels to match predictions batch size\n",
    "        labels = labels.view(-1)  # Flatten the labels to match batch size (flatten into a vector)\n",
    "        \n",
    "        # Ensure predictions have the shape [batch_size, num_classes]\n",
    "        predictions = predictions.view(-1)  # Flatten predictions as necessary\n",
    "        #print(\"Predictions: \", predictions[0:5])\n",
    "        #print(\"Labels     : \",labels[0:5])\n",
    "        print(\"Predictions: \", predictions[0:5])\n",
    "        print(\"Labels     : \",labels[0:5])\n",
    "        # Compute loss\n",
    "        loss = model.criterion(predictions, labels)\n",
    "        if epoch+1 == num_epochs:\n",
    "            print(\"Predictions: \", predictions[0:5])\n",
    "            print(\"Labels     : \",labels[0:5])\n",
    "            print(\"Loss: \", loss.item())\n",
    "        total_loss += loss.item()\n",
    "        k = k+1\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        model.optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss/k:.4f}\")\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        k = 0\n",
    "        for (his_input_title, pred_input_title), labels in val_dataloader:\n",
    "            # Move tensors to the appropriate device\n",
    "            # Convert numpy arrays to PyTorch tensors and move to the appropriate device\n",
    "            his_input_title = torch.tensor(his_input_title).to(device)\n",
    "            pred_input_title = torch.tensor(pred_input_title).to(device)\n",
    "            labels = torch.tensor(labels).to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            predictions = model(his_input_title, pred_input_title)\n",
    "\n",
    "            labels = labels.view(-1)  # Flatten the labels to match batch size (flatten into a vector)\n",
    "        \n",
    "            # Ensure predictions have the shape [batch_size, num_classes]\n",
    "            predictions = predictions.view(-1)  # Flatten predictions as necessary\n",
    "            print(\"Predictions: \", predictions[0:5])\n",
    "            print(\"Labels     : \",labels[0:5])\n",
    "            # Compute loss\n",
    "            loss = model.criterion(predictions, labels)\n",
    "            if epoch+1 == num_epochs:\n",
    "                print(\"Predictions: \", predictions[0:5])\n",
    "                print(\"Labels     : \",labels[0:5])\n",
    "                print(\"Loss: \", loss.item())\n",
    "            val_loss += loss.item()\n",
    "            k = k+1\n",
    "\n",
    "        print(f\"Validation Loss: {val_loss/k:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[320, 320, 320, 280]\n",
      "[64.0, 64.0, 64.0, 56.0]\n",
      "Average AUC Score: 0.6648587596659759\n",
      "Average Accuracy: 77.67\n"
     ]
    }
   ],
   "source": [
    "auc_metric = AucScore()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_true_total = []\n",
    "    y_pred_total = []\n",
    "    acc = []\n",
    "    sum = []\n",
    "    sum_1 = []\n",
    "    for (his_input_title, pred_input_title), labels in train_dataloader:\n",
    "        # Move tensors to the appropriate device\n",
    "        # Convert numpy arrays to PyTorch tensors and move to the appropriate device\n",
    "        his_input_title = torch.tensor(his_input_title).to(device)\n",
    "        pred_input_title = torch.tensor(pred_input_title).to(device)\n",
    "        labels = torch.tensor(labels).to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        predictions = model(his_input_title, pred_input_title)\n",
    "\n",
    "        labels = labels.view(-1)  # Flatten the labels to match batch size (flatten into a vector)\n",
    "        sum.append(len(labels.numpy()))   \n",
    "        sum_1.append(np.sum(labels.numpy()))\n",
    "        # Ensure predictions have the shape [batch_size, num_classes]\n",
    "        predictions = predictions.view(-1)\n",
    "        \n",
    "        y_pred_total.append( predictions.numpy() )\n",
    "        y_true_total.append( labels.numpy() )\n",
    "        \n",
    "        acc.append(np.sum( (predictions.numpy() > 0.5) == labels.numpy()) / len(labels.numpy()) )\n",
    "   \n",
    "    print(sum)    \n",
    "    print(sum_1)\n",
    "    auc_value = auc_metric.calculate(y_true_total, y_pred_total)\n",
    "    print(\"Average AUC Score:\", auc_value)\n",
    "    print(\"Average Accuracy:\", np.round(np.mean(acc)*100,2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n"
     ]
    }
   ],
   "source": [
    "a = 320+ 320+ 320+ 280\n",
    "b = 64.0+ 64.0+ 64.0+ 56.0\n",
    "num_of_zero = a-b\n",
    "print(num_of_zero/a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
